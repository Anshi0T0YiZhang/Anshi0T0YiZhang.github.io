---
layout:     post
title:      "Java基础"
subtitle:   " \"好好学习，天天向上\""
date:       2019-03-11 00:00:00
author:     "WQ"
header-img: "img/blogImg/2019-03-11-1.jpg"
catalog: true
tags:
    - Java
---

# JAVA 1.8 源码

声明：部分内容来自互联网，由于编写时间较长，具体参考文章早已遗忘，故若有版权问题请和我联系。

## Enum

Java中的枚举，在定义类的时候使用关键字`enum`，在反编译之后其实就是普通的class，所以枚举类也就是一个语法糖。（注意：IDEA自带的反编译器看不出来，需要使用java自带的javap，命令`javap -verbose Test.class`）

```java
public enum Test {
    P;
}

// public final class com.go2going.Test extends java.lang.Enum<com.go2going.Test>
```

`java.lang.Enum`类实现Comparable和Serializable接口，同时可以看到枚举类被加上了final标记，而我们在使用枚举时所用的属性都可以在Enum类中找到。

定义的枚举常量，使用的是static final，且使用static代码块进行初始化，所以枚举类是线程安全的（类加载过程是线程安全的）

有几处需要注意的地方：

1. 自定义的枚举类不支持equals,hashCode,clone方法的覆写（被标记为final了）
2. clone方法是不支持的
3. Serializable接口被使用的两个方法（readObject，readObjectNoData）都被覆写了
4. finalize方法被定义为空方法，且为final

在序列化这里需要强调下，在JVM规范中每一个枚举类型及其定义的枚举变量在JVM中都是唯一的，所以其在序列化上也有特殊的处理。

## Process

直接使用Process比较少见，大多数情况下方式如下：

```java
Runtime runtime = Runtime.getRuntime();
String cmd = "pwd";
Process process = runtime.exec(cmd);
```

而这里的exec实际使用的就是ProcessBuilder创建的Process类:

```java
 public Process exec(String[] cmdarray, String[] envp, File dir)
        throws IOException {
        return new ProcessBuilder(cmdarray)
            .environment(envp)
            .directory(dir)
            .start();
    }
```

相对重要的方法都是native方法，所以这里需要学习的重点还是方法注释，需要有几点注意的点：

1. 创建的子进程没有console或terminal，且不同平台对于输入输出流有缓存限制，所以如果无法及时的写入输入流或读取输出流都会导致子进程阻塞甚至死锁
2. 子进程是异步执行的，所以即使创建的对象被回收了，依然可以执行

源码中有一个值得学习的地方：

```java
// 由于这个正则表达式不一定会被用到所以使用了懒加载的方式创建
private static class LazyPattern {
        // Escape-support version:
        //    "(\")((?:\\\\\\1|.)+?)\\1|([^\\s\"]+)";
        private static final Pattern PATTERN =
            Pattern.compile("[^\\s\"]+|\"[^\"]*\"");
    };
```

## Socket

Java的Socket的默认实现是SocketImpl，并且可以通过SocketImplFactory实现定制化的Socket。下面所描述的都是JDK默认实现。

默认实现使用了jre/bin/net.dll的本地文件。在java中于操作系统的socket表示方式是使用FileDescriptor类，该类保存nativeID，该参数是C使用JNI进行设置的。

对于Input/OutputStream定制了SocketXXStream，其read和write都是native代码。

## ArrayList

实现List接口，是顺序容器，底层使用Object数据，所以可以放入null，线程不安全，多线程访问需要使用Vector代替。

```java
// 数组扩容为原来的1.5倍，创建一个新数组，然后将原来的拷贝进去
private void grow(int minCapacity) {
    // overflow-conscious code
    int oldCapacity = elementData.length;
    int newCapacity = oldCapacity + (oldCapacity >> 1);
    if (newCapacity - minCapacity < 0)
        newCapacity = minCapacity;
    if (newCapacity - MAX_ARRAY_SIZE > 0)
        newCapacity = hugeCapacity(minCapacity);
    // minCapacity is usually close to size, so this is a win:
    elementData = Arrays.copyOf(elementData, newCapacity);
}
//删除index位置的元素，需要将后面的所有元素前移，并将最后一个元素设置为null，使其能被GC
public E remove(int index) {
        rangeCheck(index);

        modCount++;
        E oldValue = elementData(index);

        int numMoved = size - index - 1;
        if (numMoved > 0)
            System.arraycopy(elementData, index+1, elementData, index,
                             numMoved);
        elementData[--size] = null; // clear to let GC do its work

        return oldValue;
    }
```

对于add(int index,E e)将元素插入到数组的特定位置，需要先移动，然后 完成插入操作

## LinkedList

内部数据结构使用双向链表，可当队列或者栈，本身是非线程安全的。

```java
//链表节点
private static class Node<E> {
    E item;
    Node<E> next;
    Node<E> prev;

    Node(Node<E> prev, E element, Node<E> next) {
        this.item = element;
        this.next = next;
        this.prev = prev;
    }
}

public void add(int index, E element) {
    // 判断是否越界
    checkPositionIndex(index);

    if (index == size)
        //这个操作很简单，添加到链表的尾部
        linkLast(element);
    else
        linkBefore(element, node(index));
}
//返回index位置的node
Node<E> node(int index) {
    // assert isElementIndex(index);
	//判断index在前半部分还是后半部分，一种搜索优化
    if (index < (size >> 1)) {
        Node<E> x = first;
        for (int i = 0; i < index; i++)
            x = x.next;
        return x;
    } else {
        Node<E> x = last;
        for (int i = size - 1; i > index; i--)
            x = x.prev;
        return x;
    }
}
//原本index处的node后移，操作还是很简单的
void linkBefore(E e, Node<E> succ) {
    // assert succ != null;
    final Node<E> pred = succ.prev;
    final Node<E> newNode = new Node<>(pred, e, succ);
    succ.prev = newNode;
    if (pred == null)
        first = newNode;
    else
        pred.next = newNode;
    size++;
    modCount++;
}
//删除节点
public E remove(int index) {
    checkElementIndex(index);
    return unlink(node(index));
}
//这里要注意，对于删除的x元素其pre，next和item都得设置为null，使其能被GC
E unlink(Node<E> x) {
    // assert x != null;
    final E element = x.item;
    final Node<E> next = x.next;
    final Node<E> prev = x.prev;

    if (prev == null) {
        first = next;
    } else {
        prev.next = next;
        x.prev = null;
    }

    if (next == null) {
        last = prev;
    } else {
        next.prev = prev;
        x.next = null;
    }

    x.item = null;
    size--;
    modCount++;
    return element;
}
```

如果想把linkedList作为Deque使用的话，其方法参考ArrayDeque，并且如果作为栈或队列使用的话，ArrayDeque更高效。

## ArrayDeque

底层数据结构是数组，同时为了支持数组两端插入或删除元素的需求，这里使用了循环数组，该类是线程不安全的，不能添加null元素。具体方法使用这里就不罗列了，主要看下代码：

```java
//三个属性，head和tail表示数组中元素的开始和结束指针
transient Object[] elements;
transient int head;
transient int tail;
// 数据的size必须是2的倍数，所以这里会对初始化的size重新设置
private static int calculateSize(int numElements) {
    int initialCapacity = MIN_INITIAL_CAPACITY;
    // Find the best power of two to hold elements.
    // Tests "<=" because arrays aren't kept full.
    if (numElements >= initialCapacity) {
        initialCapacity = numElements;
        initialCapacity |= (initialCapacity >>>  1);
        initialCapacity |= (initialCapacity >>>  2);
        initialCapacity |= (initialCapacity >>>  4);
        initialCapacity |= (initialCapacity >>>  8);
        initialCapacity |= (initialCapacity >>> 16);
        initialCapacity++;

        if (initialCapacity < 0)   // Too many elements, must back off
            initialCapacity >>>= 1;// Good luck allocating 2 ^ 30 elements
    }
    return initialCapacity;
}

public void addFirst(E e) {
    if (e == null)
        throw new NullPointerException();
    //这里的代码很特别，其目的是防止数组越界
    //由于数组的长度是2的倍数，length-1表示的是数组index的最大值，head-1&上之后保证了结果最大是length-1；如果head-1为-1（只可能为-1），&完之后就是length-1,保证不会越界
    elements[head = (head - 1) & (elements.length - 1)] = e;
    //注意tail总是指向下一个可插入的空位，所以上面就保证了插入不会覆盖
    //当tail==head表示满了，需要扩容，X2
    if (head == tail)
        doubleCapacity();
}

//head==tail才会扩容
private void doubleCapacity() {
    assert head == tail;
    int p = head;
    int n = elements.length;
    int r = n - p; // number of elements to the right of p
    int newCapacity = n << 1;//X2
    if (newCapacity < 0)//越界
        throw new IllegalStateException("Sorry, deque too big");
    Object[] a = new Object[newCapacity];
    //拷贝分为两部分，先拷贝head到length,再拷贝0到tail（head==tail）
    System.arraycopy(elements, p, a, 0, r);
    System.arraycopy(elements, 0, a, r, p);
    elements = a;
    head = 0;
    tail = n;
}

public void addLast(E e) {
    if (e == null)
        throw new NullPointerException();
    //由于tail总指向下个可插入的位置，所以直接插入就行
    elements[tail] = e;
    //tail+1后得判断是否越界，&效率更高
    if ( (tail = (tail + 1) & (elements.length - 1)) == head)
        doubleCapacity();
}
//获取并删除头部元素
public E pollFirst() {
    int h = head;
    @SuppressWarnings("unchecked")
    E result = (E) elements[h];
    // Element is null if deque empty
    if (result == null)
        return null;
    elements[h] = null;     // Must null out slot
    //防止越界
    head = (h + 1) & (elements.length - 1);
    return result;
}
//获取并删除尾部元素
public E pollLast() {
    //tail表示下个插入的位置，所以需要-1
    int t = (tail - 1) & (elements.length - 1);
    @SuppressWarnings("unchecked")
    E result = (E) elements[t];
    if (result == null)
        return null;
    elements[t] = null;
    tail = t;
    return result;
}
```

## TreeMap(TreeSet)

TreeSet的实现和Treemap相同，只是忽略了value，所以只要看TreeMap即可。

Treemap实现Sortmap接口，能对key进行排序，由于key可以比较所以就有了NavigableMap中的一些方法，如floorXX、ceilingXX等方法，这些还是很好用的。

底层使用红黑树

```java
//简略形式
private static final boolean RED   = false;
private static final boolean BLACK = true;
static final class Entry<K,V> implements Map.Entry<K,V> {
        K key;
        V value;
        Entry<K,V> left;
        Entry<K,V> right;
        Entry<K,V> parent;
        boolean color = BLACK;
}

//左旋，对照着下面的图理解就好，不能遗漏
private void rotateLeft(Entry<K,V> p) {
    if (p != null) {
        Entry<K,V> r = p.right;
        p.right = r.left;
        if (r.left != null)
            r.left.parent = p;
        r.parent = p.parent;
        if (p.parent == null)
            root = r;
        else if (p.parent.left == p)
            p.parent.left = r;
        else
            p.parent.right = r;
        r.left = p;
        p.parent = r;
    }
}

/** From CLR */
//右旋
private void rotateRight(Entry<K,V> p) {
    if (p != null) {
        Entry<K,V> l = p.left;
        p.left = l.right;
        if (l.right != null) l.right.parent = p;
        l.parent = p.parent;
        if (p.parent == null)
            root = l;
        else if (p.parent.right == p)
            p.parent.right = l;
        else p.parent.left = l;
        l.right = p;
        p.parent = l;
    }
}
```

对于旋转的话主要理解还是需要画图，列出 下面点的关系，就很容易理解这个过程了（右旋和这个相反）![TreeMap_rotateLeft.png](https://github.com/CarpenterLee/JCFInternals/blob/master/PNGFigures/TreeMap_rotateLeft.png?raw=true)

后续节点	，对于给定的节点t，其后续（树中大于t的最小元素），下面两种情况很好理解

1. 若t的右子树不为null，则其后续为右子树中最小的元素（右子树最左边的元素）
2. 若t的右子树为null，则其后续为其第一个向左走的祖先

```java
static <K,V> TreeMap.Entry<K,V> successor(Entry<K,V> t) {
    if (t == null)
        return null;
    else if (t.right != null) {
        //第一种情况
        Entry<K,V> p = t.right;
        while (p.left != null)
            p = p.left;
        return p;
    } else {
        //第二种情况，这里的判断需要注意
        Entry<K,V> p = t.parent;
        Entry<K,V> ch = t;
        while (p != null && ch == p.right) {
            ch = p;
            p = p.parent;
        }
        return p;
    }
}
//
//get方法，主要调用的是这个，简单的二叉树查找
final Entry<K,V> getEntry(Object key) {
    // Offload comparator-based version for sake of performance
    if (comparator != null)
        return getEntryUsingComparator(key);
    if (key == null)
        throw new NullPointerException();
    @SuppressWarnings("unchecked")
    Comparable<? super K> k = (Comparable<? super K>) key;
    Entry<K,V> p = root;
    while (p != null) {
        int cmp = k.compareTo(p.key);
        if (cmp < 0)
            p = p.left;
        else if (cmp > 0)
            p = p.right;
        else
            return p;
    }
    return null;
}
//
public V put(K key, V value) {
    Entry<K,V> t = root;
    //树为null，直接添加一个root
    if (t == null) {
        //类型检查，Comparablenull
        compare(key, key); // type (and possibly null) check

        root = new Entry<>(key, value, null);
        size = 1;
        modCount++;
        return null;
    }
    //记录最后一次比较的值
    int cmp;
    Entry<K,V> parent;
    // split comparator and comparable paths
    Comparator<? super K> cpr = comparator;
    //if和else的区别在于比较方式
    //在递归比较的过程中，如果找到了就覆盖，没找到的话，就会将parent更新为合适的值，插入一个entry
    if (cpr != null) {
        do {
            parent = t;
            cmp = cpr.compare(key, t.key);
            if (cmp < 0)
                t = t.left;
            else if (cmp > 0)
                t = t.right;
            else
                //key在树中存在就覆盖之前的值
                return t.setValue(value);
        } while (t != null);
    }
    else {
        if (key == null)
            throw new NullPointerException();
        @SuppressWarnings("unchecked")
        Comparable<? super K> k = (Comparable<? super K>) key;
        do {
            parent = t;
            cmp = k.compareTo(t.key);
            if (cmp < 0)
                t = t.left;
            else if (cmp > 0)
                t = t.right;
            else
                return t.setValue(value);
        } while (t != null);
    }
    Entry<K,V> e = new Entry<>(key, value, parent);
    //插入新值
    if (cmp < 0)
        parent.left = e;
    else
        parent.right = e;
    //如果破坏了红黑树的约束条件，需要通过旋转或变色修复
    //这里是难点
    fixAfterInsertion(e);
    size++;
    modCount++;
    return null;
}
```

最关键的两个方法fixAfterDeletion和fixAfterInsertion这两个方法就不看了，情况太多，我也很混乱。

## HashMap(HashSet)

HashSet内部使用的就是HashMap，只是忽略了HashMap的value；运行key和value为null；

在jdk1.8中HashMap内部使用了两种数据结构，buckets数组+链表和buckets数组+红黑树

```java
//map创建时使用的是数据+链表，和初始化大小无关
//当map中链表的长度超过8个就使用数据+红黑树
static final int TREEIFY_THRESHOLD = 8;

///当map中链表的长度少于6个就使用数据+链表
static final int UNTREEIFY_THRESHOLD = 6;
```

对于第一种数据结构，其结构示意图如下：

![HashMap_base.png](https://github.com/CarpenterLee/JCFInternals/blob/master/PNGFigures/HashMap_base.png?raw=true)

当hash冲突的时候回使用链表存储KV；有两个比较重要的参数初始化容量（initial size）和负载系数（load factor），当存入的KV超过initial_size*load_factor时就会进行扩容，即数组大小X1.5倍，这个过程需要reHash，这个操作很耗时的，所以对于参数的设置很重要，如果预先知道放入容器的数量，一定要知道容量，避免reHash。另外，由于需要使用hash和equals方法，所以对自定义的key的这两个方法，一定要重写。

```java
// get的方法，hash是key对应的hash值 
final Node<K,V> getNode(int hash, Object key) {
    Node<K,V>[] tab; Node<K,V> first, e; int n; K k;
    if ((tab = table) != null && (n = tab.length) > 0 &&
        (first = tab[(n - 1) & hash]) != null) {
        //这里的&防止越界，可以这么干的原因是数组长度是2的倍数
        //如果链表的first的hash相等
        if (first.hash == hash && // always check first node
            ((k = first.key) == key || (key != null && key.equals(k))))
            return first;
        if ((e = first.next) != null) {
            //链表的第一个不等，判断是不是红黑树
            if (first instanceof TreeNode)
                return ((TreeNode<K,V>)first).getTreeNode(hash, key);
            //遍历链表
            do {
                if (e.hash == hash &&
                    ((k = e.key) == key || (key != null && key.equals(k))))
                    return e;
            } while ((e = e.next) != null);
        }
    }
    return null;
}
//1.8版本加了些方法，方法多了几个参数
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
               boolean evict) {
    Node<K,V>[] tab; Node<K,V> p; int n, i;
    if ((tab = table) == null || (n = tab.length) == 0)
        n = (tab = resize()).length;
    //如果数组是null，直接创界个节点放进去
    if ((p = tab[i = (n - 1) & hash]) == null)
        tab[i] = newNode(hash, key, value, null);
    else {
        //e是key在map中对于的oldValue
        Node<K,V> e; K k;
        //如果链表的第一个符合key，那么获取这个oldValue
        if (p.hash == hash &&
            ((k = p.key) == key || (key != null && key.equals(k))))
            e = p;
        else if (p instanceof TreeNode)
            //红黑树
            e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
        else {
            //遍历链表
            for (int binCount = 0; ; ++binCount) {
                //找到链表的结尾都没有找到，那就说明这个key在map中没有，直接new接到最后
                if ((e = p.next) == null) {
                    p.next = newNode(hash, key, value, null);
                    if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                        //将链表改为红黑树
                        treeifyBin(tab, hash);
                    break;
                }
                //找到了的话，break
                if (e.hash == hash &&
                    ((k = e.key) == key || (key != null && key.equals(k))))
                    break;
                p = e;
            }
        }
        //将oldValue替换为新的
        if (e != null) { // existing mapping for key
            V oldValue = e.value;
            if (!onlyIfAbsent || oldValue == null)
                e.value = value;
            //预留的方法回调
            afterNodeAccess(e);
            return oldValue;
        }
    }
    ++modCount;
    //扩容
    if (++size > threshold)
        resize();
    //预留的方法回调
    afterNodeInsertion(evict);
    return null;
}

final Node<K,V> removeNode(int hash, Object key, Object value,
                           boolean matchValue, boolean movable) {
    Node<K,V>[] tab; Node<K,V> p; int n, index;
    //p表示头部
    if ((tab = table) != null && (n = tab.length) > 0 &&
        (p = tab[index = (n - 1) & hash]) != null) {
        //node 先找到需要被删除的节点
        Node<K,V> node = null, e; K k; V v;
        //头节点就是要删除的key
        if (p.hash == hash &&
            ((k = p.key) == key || (key != null && key.equals(k))))
            node = p;
        else if ((e = p.next) != null) {
            //p.next为null，那就说明key在map中不存在
            if (p instanceof TreeNode)
                //红黑树查找
                node = ((TreeNode<K,V>)p).getTreeNode(hash, key);
            else {
                //链表查找
                do {
                    if (e.hash == hash &&
                        ((k = e.key) == key ||
                         (key != null && key.equals(k)))) {
                        node = e;
                        break;
                    }
                    p = e;
                } while ((e = e.next) != null);
            }
        }
        if (node != null && (!matchValue || (v = node.value) == value ||
                             (value != null && value.equals(v)))) {
            if (node instanceof TreeNode)
                //红黑树的删除
                ((TreeNode<K,V>)node).removeTreeNode(this, tab, movable);
            else if (node == p)
                //如果是数组的头部，直接赋值
                tab[index] = node.next;
            else
                //否则就是链表
                p.next = node.next;
            ++modCount;
            --size;
            //预留的回调
            afterNodeRemoval(node);
            return node;
        }
    }
    return null;
}
```



## LinkedHashMap(LinkedHashSet)

LinkedHashSet就不说了。

LinkedHashMap是HashMap的子类，通过名字就知道这个类是有序的（保留插入顺序），使用双向链表连接entry，使其在迭代的时候能够保证是entry的插入顺序，同时还有一个好处由于该类保存了head和tail，所以在遍历的时候无需像HashMap那样遍历整个Entry数组。由于其主要方法和HashMap一直所以这里就不细说了。

有个protected的removeEldestEntry方法，该方法在插入node之后会被调用，当方法返回true表示会删除最先被插入的元素。

```java
void afterNodeInsertion(boolean evict) { // possibly remove eldest
    LinkedHashMap.Entry<K,V> first;
    
    //判断是否清除最老的node
    if (evict && (first = head) != null && removeEldestEntry(first)) {
        K key = first.key;
        removeNode(hash(key), key, null, false, true);
    }
}
```



## Reflection

java反射的核心是Class类，这个类的注释很有帮助：

1. 枚举是一个class，注解是一个接口，数组是一个class
2. 所以基本类型和Void类型都是class
3. Class对象没有public构造器，Class对象的构造是由JVM完成的（JVMTI jvm tool  interface）

在Class中会保存反射的结果，缓存对象以Class内部类ReflectionData对象进行保存(使用了SoftReference)。缓存默认情况下是开启的，但是可以通过系统属性`sun.reflect.noCaches`设置为false。

在ReflectionData中的classRedefinedCount属性用于记录在JVM中该类或父类重定义的次数，主要用于判断缓存的有效性。

class的许多get方法都使用了copy的方式获取类的属性，如方法，类属性，注解，构造器。

## BufferedInputStream

该类public方法中，除了close方法都加上了synchronized，所以该类是线程安全的。

缓存数组最大值为int的最大值减去8，因为JVM对于对象需要8个字节保存对象头信息。



```java
// 填充数据
private void fill() throws IOException {
    byte[] buffer = getBufIfOpen();//获取缓存数组
    if (markpos < 0)//没有标记位置的话markpos=-1，不需要再次读取标记处的数据，所以整个缓冲区直接覆盖写入即可
        pos = 0;            /* no mark: throw away the buffer */
    else if (pos >= buffer.length)  /* no room left in buffer */
        // buffer的数据少于pos
        if (markpos > 0) {  /* can throw away early part of the buffer */
            // 将缓存中之前的数据丢弃掉，保留从markpos开始的数据
            int sz = pos - markpos;
            System.arraycopy(buffer, markpos, buffer, 0, sz);
            pos = sz;
            markpos = 0;
        } else if (buffer.length >= marklimit) {
            //缓存数据大小超过限制，丢弃掉所有已缓存数据，即将pos设置为0
            markpos = -1;   /* buffer got too big, invalidate mark */
            pos = 0;        /* drop buffer contents */
        } else if (buffer.length >= MAX_BUFFER_SIZE) {
            throw new OutOfMemoryError("Required array size too large");
        } else {            /* grow buffer */
            //缓存数组扩容，扩大到原来的2倍
            int nsz = (pos <= MAX_BUFFER_SIZE - pos) ?
                    pos * 2 : MAX_BUFFER_SIZE;
            if (nsz > marklimit)
                nsz = marklimit;
            byte nbuf[] = new byte[nsz];
            System.arraycopy(buffer, 0, nbuf, 0, pos);
            //由于close方法不是sychronized方法所以这里使用CAS检查是否有关闭
            if (!bufUpdater.compareAndSet(this, buffer, nbuf)) {
                // Can't replace buf if there was an async close.
                // Note: This would need to be changed if fill()
                // is ever made accessible to multiple threads.
                // But for now, the only way CAS can fail is via close.
                // assert buf == null;
                throw new IOException("Stream closed");
            }
            buffer = nbuf;
        }
    count = pos;
    //读取数据
    int n = getInIfOpen().read(buffer, pos, buffer.length - pos);
    if (n > 0)
        count = n + pos;
}
```

这里需要注意的一点是，inputStream的read方法是阻塞的，但是available方法是非阻塞的。

```java
public synchronized long skip(long n) throws IOException {
    getBufIfOpen(); // Check for closed stream
    if (n <= 0) {
        return 0;
    }
    long avail = count - pos;

    if (avail <= 0) {
        // If no mark position set then don't keep in buffer
        if (markpos <0)
            //调用InputStream的skip方法，这个方法会创建一个临时数组，然后不停的需要跳过的字节读入这个数组，相当于是读取之后丢弃数据
            return getInIfOpen().skip(n);

        // Fill in buffer to save bytes for reset
        fill();
        avail = count - pos;
        if (avail <= 0)
            return 0;
    }

    long skipped = (avail < n) ? avail : n;
    pos += skipped;
    return skipped;
}
```

这里的skip方法是较为低效的，例如FileInputStream在skip的实现是使用native方法，因为操作系统对文件系统提供了文件指针，可以直接移动文件指针便可以达到跳过字节的效果。

## AsynchronousFileChannel

FileChannel为同步非阻塞，而AsynchronousFileChannel为真正的异步操作。

这里需要解释下：

1. 同步/异步：同步表示调用者主动等待调用结果；异步表示调用者在调用之后直接返回了，没有等待调用结果，被调用者通过状态、通知、回调函数来告知调用者
2. 阻塞/非阻塞（都是同步IO）：表示程序在等待调用结果时的状态，阻塞调用表示程序在等待返回结果前线程会被挂起；非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程

在使用时，只能通过AsynchronousFileChannel的两个静态open方法创建

```java
public static AsynchronousFileChannel open(Path file,
                                           Set<? extends OpenOption> options,
                                           ExecutorService executor,
                                           FileAttribute<?>... attrs)
    throws IOException
{
    FileSystemProvider provider = file.getFileSystem().provider();
    return provider.newAsynchronousFileChannel(file, options, executor, attrs);
}
```

这里获取FileSystemProvider是和平台有关的，在windows中FileSystem是WindowsFileSystem，provider是WindowsFileSystemProvider；在linux平台中FileSystem是LinuxFileSystem，provider是LinuxFileSystemProvider。这个都是通过本地文件提供的，所以在windows中的jdk没有linux版本的相关文件。

executor默认情况下是空的，但是在沿着源码看下会，以windows平台为例，代码如下：

```java
static ThreadPool createDefault() {
    int var0 = getDefaultThreadPoolInitialSize();
    if (var0 < 0) {
        var0 = Runtime.getRuntime().availableProcessors();
    }

    ThreadFactory var1 = getDefaultThreadPoolThreadFactory();
    if (var1 == null) {
        var1 = defaultThreadFactory();
    }

    ExecutorService var2 = Executors.newCachedThreadPool(var1);
    return new ThreadPool(var2, false, var0);
}
```

代码内部会创建一个线程池，线程数为cpu核心数。其异步的实现方式通过线程池去操作IO，执行完毕后再通过Future或回调函数通知我们，但是这里的readFile的方法是WindowsAsynchronousFileChannelImpl的native方法，所以具体的实现还是和平台有关的。

## ThreadPool

构造器的话参考下面ScheduledThreadPool中的。

这里说下RejectedExecutionHandler，在jdk的内部实现中有4个人：

1. AbortPolicy：拒绝时抛出异常（默认策略）
2. CallerRunsPolicy：在调用这个类方法的线程中直接运行
3. DiscardOldestPolicy：对拒绝任务不抛弃，而是抛弃队列里面等待最久的一个线程，然后把拒绝任务加到队列
4. DiscardPolicy：对拒绝任务直接无声抛弃，没有异常信息

默认的线程池工厂是`java.util.concurrent.Executors.DefaultThreadFactory`,很简单这里就不展开了。

线程池的一个重要变量是ctl，其主要作用是控制线程池生命周期和记录有效线程数，一共有5个状态。这里的技巧性很强，用一个 变量表示两个含义。

```java
private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));
private static final int COUNT_BITS = Integer.SIZE - 3;//29
private static final int CAPACITY   = (1 << COUNT_BITS) - 1;//低29位存储线程数，所以最大线程数为2^29-1
//高三位表示运行状态
private static final int RUNNING    = -1 << COUNT_BITS;
private static final int SHUTDOWN   =  0 << COUNT_BITS;
private static final int STOP       =  1 << COUNT_BITS;
private static final int TIDYING    =  2 << COUNT_BITS;
private static final int TERMINATED =  3 << COUNT_BITS;

//做了很多校验工作，其目的是为了处理一些奇葩场景，但是代码注释没有列举，所以也不用在这里深究
public void execute(Runnable command) {
    if (command == null)
        throw new NullPointerException();
    int c = ctl.get();
    //当前线程数小于核心线程数
    if (workerCountOf(c) < corePoolSize) {
        //添加工作线程
        if (addWorker(command, true))
            return;
        //添加失败的话，重新获取当前状态
        c = ctl.get();
    }
    //将任务添加到队列中
    if (isRunning(c) && workQueue.offer(command)) {
        int recheck = ctl.get();
        //线程池状态不为running，删除当前任务
        if (! isRunning(recheck) && remove(command))
            reject(command);
        else if (workerCountOf(recheck) == 0)
            //虽然任务放到队列中去了，但是线程数为0，所以需要创建个线程
            addWorker(null, false);
    }
    else if (!addWorker(command, false))//重试
        reject(command);
}
//这里core参数用于判断最大线程数的，为true表示以coreSize为最大值，false表示以maximumPoolSize为最大值
private boolean addWorker(Runnable firstTask, boolean core) {
    retry:
    for (;;) {
        int c = ctl.get();
        int rs = runStateOf(c);
        // Check if queue empty only if necessary.
        if (rs >= SHUTDOWN &&
            ! (rs == SHUTDOWN &&
               firstTask == null &&
               ! workQueue.isEmpty()))
            return false;

        for (;;) {
            int wc = workerCountOf(c);
            //超过最大线程数
            if (wc >= CAPACITY ||
                wc >= (core ? corePoolSize : maximumPoolSize))
                return false;
            //线程数+1
            if (compareAndIncrementWorkerCount(c))
                //退出for
                break retry;
            c = ctl.get();  // Re-read ctl
            if (runStateOf(c) != rs)
                //不断重试
                continue retry;
            // else CAS failed due to workerCount change; retry inner loop
        }
    }
	
    //下面执行线程的创建
    boolean workerStarted = false;
    boolean workerAdded = false;
    Worker w = null;
    try {
        //创建worker，该类中记录一些中断状态并提供锁,对线程的简单包装，代表线程池中的线程
        w = new Worker(firstTask);
        final Thread t = w.thread;
        if (t != null) {
            final ReentrantLock mainLock = this.mainLock;
            mainLock.lock();
            try {
                // Recheck while holding lock.
                // Back out on ThreadFactory failure or if
                // shut down before lock acquired.
                int rs = runStateOf(ctl.get());
			    //线程池状态检查
                if (rs < SHUTDOWN ||
                    (rs == SHUTDOWN && firstTask == null)) {
                    if (t.isAlive()) // precheck that t is startable
                        throw new IllegalThreadStateException();
                    //添加到池中（HashSet）
                    workers.add(w);
                    int s = workers.size();
                    if (s > largestPoolSize)
                        largestPoolSize = s;
                    workerAdded = true;
                }
            } finally {
                mainLock.unlock();
            }
            //添加work成功，执行这个任务
            if (workerAdded) {
                t.start();
                workerStarted = true;
            }
        }
    } finally {
        //添加失败，加到失败列表中
        if (! workerStarted)
            addWorkerFailed(w);
    }
    return workerStarted;
}

//这里解决了一个困惑，任务队列中的任务是如何执行的？
//当我们创建work的时候就会调用其内部的thread并启动，其run方法就是调用这个runWorker，而这个方法是while循环，所以只要队列中有任务就会一直调用getTask获取并运行，返回null就结束
//那么当线程数大于coreSize时，线程如何减少的呢，如果一直等待任务的话？
//这个需要看getTask的逻辑，如果队列中没有任务的话，getTask返回null，这会释放这个线程，如果没有超过coreSize大小即使队列为null，也会一直等待
final void runWorker(Worker w) {
    Thread wt = Thread.currentThread();
    Runnable task = w.firstTask;
    w.firstTask = null;
    w.unlock(); // allow interrupts
    boolean completedAbruptly = true;
    try {
        while (task != null || (task = getTask()) != null) {
            w.lock();
            // If pool is stopping, ensure thread is interrupted;
            // if not, ensure thread is not interrupted.  This
            // requires a recheck in second case to deal with
            // shutdownNow race while clearing interrupt
            if ((runStateAtLeast(ctl.get(), STOP) ||
                 (Thread.interrupted() &&
                  runStateAtLeast(ctl.get(), STOP))) &&
                !wt.isInterrupted())
                wt.interrupt();
            try {
                //预留的通知
                beforeExecute(wt, task);
                Throwable thrown = null;
                try {
                    task.run();
                } catch (RuntimeException x) {
                    thrown = x; throw x;
                } catch (Error x) {
                    thrown = x; throw x;
                } catch (Throwable x) {
                    thrown = x; throw new Error(x);
                } finally {
                    //预留的通知
                    afterExecute(task, thrown);
                }
            } finally {
                task = null;
                //worker的计数器
                w.completedTasks++;
                w.unlock();
            }
        }
        completedAbruptly = false;
    } finally {
        //线程退出线程池，做一些清理工作
        //注意这里completedAbruptly，如果上面执行task出错，那么completedAbruptly为true
        //在这个方法中会创建一个新的线程（线程“重生”）
        processWorkerExit(w, completedAbruptly);
    }
}

//从任务队列获取任务，然后去执行，这里的逻辑很关键
private Runnable getTask() {
    boolean timedOut = false; // Did the last poll() time out?

    for (;;) {
        int c = ctl.get();
        int rs = runStateOf(c);

        //队列中没有任务的时候返回null，且将线程计数器减一
        if (rs >= SHUTDOWN && (rs >= STOP || workQueue.isEmpty())) {
            decrementWorkerCount();
            return null;
        }

        int wc = workerCountOf(c);

        // Are workers subject to culling?
        boolean timed = allowCoreThreadTimeOut || wc > corePoolSize;
		// 允许核心线程超时或线程数大于最大线程数或队列为空
        if ((wc > maximumPoolSize || (timed && timedOut))
            && (wc > 1 || workQueue.isEmpty())) {
            if (compareAndDecrementWorkerCount(c))
                return null;
            continue;
        }

        try {
            //从队列中拿走一个任务，如果拿到的是null，就一直for
            Runnable r = timed ?
                workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) :
            workQueue.take();
            if (r != null)
                return r;
            timedOut = true;
        } catch (InterruptedException retry) {
            timedOut = false;
        }
    }
}

//submit方法在其父类AbstractExecutorService中实现的,为了实现异步的执行，会将task包装成FutureTask（RunnableFuture），然后调用execute执行（调用FutureTask的run方法，而这个方法会调用自定义的run方法），所以异步的关键在FutureTask类（该类基本都是CAS操作）
class FutureTask{//这里忽略一些无关代码
    //使用变量辨识当前任务的状态
    private volatile int state;
    //调用get获取结果的线程等待队列，使用的单链表
    private volatile WaitNode waiters;
    //构造器,支持runnable，其是就是简单的包装callable，其返回值就是参数result
    public FutureTask(Callable<V> callable) {
       //...
    }
    public FutureTask(Runnable runnable, V result) {
       //...
    }
    //关键部分
    public void run() {
        //状态校验
        if (state != NEW ||
            !UNSAFE.compareAndSwapObject(this, runnerOffset,
                                         null, Thread.currentThread()))
            return;
        try {
            Callable<V> c = callable;
            if (c != null && state == NEW) {
                V result;
                boolean ran;
                try {
                    //调用定义的call方法
                    result = c.call();
                    ran = true;
                } catch (Throwable ex) {
                    result = null;
                    ran = false;
                    setException(ex);
                }
                if (ran)
                    set(result);
            }
        } finally {
            // runner must be non-null until state is settled to
            // prevent concurrent calls to run()
            runner = null;
            // state must be re-read after nulling runner to prevent
            // leaked interrupts
            int s = state;//这里很有必要
            if (s >= INTERRUPTING)
                handlePossibleCancellationInterrupt(s);
        }
    }
    //get的核心方法
    private int awaitDone(boolean timed, long nanos)
        throws InterruptedException {
        final long deadline = timed ? System.nanoTime() + nanos : 0L;
        WaitNode q = null;
        boolean queued = false;
        for (;;) {
            //线程中断
            if (Thread.interrupted()) {
                //从链表中移除当前线程
                removeWaiter(q);
                throw new InterruptedException();
            }

            int s = state;
            //已完成
            if (s > COMPLETING) {
                if (q != null)
                    q.thread = null;
                return s;
            }
            else if (s == COMPLETING) // cannot time out yet
                //放弃cpu执行时间，因为得等待，没必要占用cpu时间片
                Thread.yield();
            else if (q == null)//状态还不对,创建node
                q = new WaitNode();
            else if (!queued)//状态还不对,尾部添加node
                queued = UNSAFE.compareAndSwapObject(this, waitersOffset,
                                                     q.next = waiters, q);
            else if (timed) {
                //等待时间过长，放弃等待
                nanos = deadline - System.nanoTime();
                if (nanos <= 0L) {
                    removeWaiter(q);
                    return state;
                }
                //放弃当前线程的cpu调度
                LockSupport.parkNanos(this, nanos);
            }
            else
                LockSupport.park(this);
        }
    }
    
   private void finishCompletion() {
        // assert state > COMPLETING;
       //唤醒所有等待的线程
        for (WaitNode q; (q = waiters) != null;) {
            if (UNSAFE.compareAndSwapObject(this, waitersOffset, q, null)) {
                for (;;) {
                    Thread t = q.thread;
                    if (t != null) {
                        q.thread = null;
                        //告诉cpu可以调度这个线程
                        LockSupport.unpark(t);
                    }
                    WaitNode next = q.next;
                    if (next == null)
                        break;
                    q.next = null; // unlink to help gc
                    q = next;
                }
                break;
            }
        }
		//预留的空方法
        done();

        callable = null;        // to reduce footprint
    }
      	
}

//获取正在运行的线程数，通过work中锁标记进行判断
public int getActiveCount() {
    final ReentrantLock mainLock = this.mainLock;
    mainLock.lock();
    try {
        int n = 0;
        for (Worker w : workers)
            if (w.isLocked())
                ++n;
        return n;
    } finally {
        mainLock.unlock();
    }
}

// 该类重写了finalize方法，调用shutdown()
```



## ScheduledThreadPool

一般通过Executors.newScheduledThreadPool(size)方法创建ScheduledThreadPoolExecutor。

```java
// 核心构造器
public ScheduledThreadPoolExecutor(int corePoolSize) {
    //这里的super指的是ThreadPoolExecutor类
    super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS,
          new DelayedWorkQueue());
}

/**
 * Creates a new {@code ThreadPoolExecutor} with the given initial
 * parameters.
 *
 * @param corePoolSize the number of threads to keep in the pool, even
 *        if they are idle, unless {@code allowCoreThreadTimeOut} is set
 * @param maximumPoolSize the maximum number of threads to allow in the
 *        pool
 * @param keepAliveTime when the number of threads is greater than
 *        the core, this is the maximum time that excess idle threads
 *        will wait for new tasks before terminating.
 * @param unit the time unit for the {@code keepAliveTime} argument
 * @param workQueue the queue to use for holding tasks before they are
 *        executed.  This queue will hold only the {@code Runnable}
 *        tasks submitted by the {@code execute} method.
 * @param threadFactory the factory to use when the executor
 *        creates a new thread
 * @param handler the handler to use when execution is blocked
 *        because the thread bounds and queue capacities are reached
 * @throws IllegalArgumentException if one of the following holds:<br>
 *         {@code corePoolSize < 0}<br>
 *         {@code keepAliveTime < 0}<br>
 *         {@code maximumPoolSize <= 0}<br>
 *         {@code maximumPoolSize < corePoolSize}
 * @throws NullPointerException if {@code workQueue}
 *         or {@code threadFactory} or {@code handler} is null
 */
public ThreadPoolExecutor(int corePoolSize,
						  int maximumPoolSize,
						  long keepAliveTime,
						  TimeUnit unit,
						  BlockingQueue<Runnable> workQueue,
						  ThreadFactory threadFactory,
						  RejectedExecutionHandler handler) {
	if (corePoolSize < 0 ||
		maximumPoolSize <= 0 ||
		maximumPoolSize < corePoolSize ||
		keepAliveTime < 0)
		throw new IllegalArgumentException();
	if (workQueue == null || threadFactory == null || handler == null)
		throw new NullPointerException();
	this.acc = System.getSecurityManager() == null ?
			null :
			AccessController.getContext();
	this.corePoolSize = corePoolSize;
	this.maximumPoolSize = maximumPoolSize;
	this.workQueue = workQueue;
	this.keepAliveTime = unit.toNanos(keepAliveTime);
	this.threadFactory = threadFactory;
	this.handler = handler;
}
```

该线程池和其他线程池的主要区别在于可以提交周期执行任务和单次延迟任务，时间的计算方式使用相对时间，而Timer类使用的是绝对时间。

延迟功能的实现在于其提交的Runable task被包装成ScheduledFutureTask，使用的是decorateTask方法(注意到这个方法的第一个参数是无效的)。

```java
public void run() {
    //判断是否是周期性的
    boolean periodic = isPeriodic();
    if (!canRunInCurrentRunState(periodic))
        cancel(false);
    else if (!periodic)
        //不是周期性任务，立即执行
        ScheduledFutureTask.super.run();
    else if (ScheduledFutureTask.super.runAndReset()) {
        //是周期性任务，执行之后重置任务
        setNextRunTime();
        reExecutePeriodic(outerTask);
    }
}
```

此外该类使用了特殊的DelayedWorkQueue，其内部使用的是堆数据结构（最小堆），这里补充一下[堆](#堆)数据结构。

其内部使用了[Leader-Follower算法](#Leader-Follower算法)（这里是一种变种）

```java
//向队列头部插入元素
public boolean offer(Runnable x) {
    if (x == null)
        throw new NullPointerException();
    RunnableScheduledFuture<?> e = (RunnableScheduledFuture<?>)x;
    final ReentrantLock lock = this.lock;
    lock.lock();
    try {
        //判断数组大小，小了就扩容
        int i = size;
        if (i >= queue.length)
            grow();
        size = i + 1;
        if (i == 0) {
            queue[0] = e;
            // 设置该Runnable的index属性
            setIndex(e, 0);
        } else {
            siftUp(i, e);
        }
        if (queue[0] == e) {
            leader = null;
            //available signal的条件：有新的task在队列头或有一个新的线程准备称为leader
            available.signal();
        }
    } finally {
        lock.unlock();
    }
    return true;
}

//容量增加50%
private void grow() {
    int oldCapacity = queue.length;
    int newCapacity = oldCapacity + (oldCapacity >> 1); // grow 50%
    if (newCapacity < 0) // overflow
        newCapacity = Integer.MAX_VALUE;
    queue = Arrays.copyOf(queue, newCapacity);
}

// 将元素添加到堆当中，并上移动，保证依然是最小堆
// k表示添加的index
private void siftUp(int k, RunnableScheduledFuture<?> key) {
    while (k > 0) {
        //获取位置k的parent节点
        int parent = (k - 1) >>> 1;
        RunnableScheduledFuture<?> e = queue[parent];
        //这里的compare实际调用的是ScheduledFutureTask的compare方法
        //比较的是延时时间，也就是所父节点的延迟时间是小的
        if (key.compareTo(e) >= 0)
            break;
        //将当前的index设置为父节点的值
        queue[k] = e;
        setIndex(e, k);
        //更新index，相当于是将不符合break条件的下移，找到合适的位置将key放进去，重新构建堆
        k = parent;
    }
    queue[k] = key;
    setIndex(key, k);
}

public RunnableScheduledFuture<?> take() throws InterruptedException {
    final ReentrantLock lock = this.lock;
    lock.lockInterruptibly();
    try {
        for (;;) {
            //获取等待事件最短的，即队列第一个元素
            RunnableScheduledFuture<?> first = queue[0];
            if (first == null)
                //没拿到，等呗
                available.await();
            else {
                //等待事件判断
                long delay = first.getDelay(NANOSECONDS);
                if (delay <= 0)
                    return finishPoll(first);
                first = null; // don't retain ref while waiting
                if (leader != null)
                    //如果有leader线程，那就等待
                    available.await();
                else {
                    //没有leader，就将当前线程作为leader,然后等待
                    Thread thisThread = Thread.currentThread();
                    leader = thisThread;
                    try {
                        available.awaitNanos(delay);
                    } finally {
                        //但是用完了得重置leader
                        if (leader == thisThread)
                            leader = null;
                    }
                }
            }
        }
    } finally {
        if (leader == null && queue[0] != null)
            available.signal();
        lock.unlock();
    }
}
```

## Streams

streams在jdk1.8中被引入，对于首次引入函数式编程，其目的在于：

1. 代码简洁
2. 多核友好（能够轻易的实现并行计算）

核心类继承体系，在BaseStream类下有4个类（AbstractPipeline排除在外），其中Stream对于Object类型，其他对应3个是基本类型（这么区分主要是返回值问题）

![stream继承体系.png](https://github.com/ted-wq-x/ted-wq-x.github.io/blob/master/img/blogImg/2018-11-29/stream%E7%BB%A7%E6%89%BF%E4%BD%93%E7%B3%BB.png?raw=true)

Stream不代表数据源，只是数据源的视图（类似），数据源包括数组，java容器，IO等。这个视图的创建可以通过：

1. 调用`Collection.stream()`或者`Collection.parallelStream()`方法
2. 调用`Arrays.stream(T[] array)`方法

Stream的操作分为两类，中间操作和结束操作，且Stream是惰性求值，只有在遇到结束操作时才会执行计算，两种操作区分的方式一般为，若方法返回值为Stream就是中间操作，其他为结束操作。所以的操作组装在`Stream Pipeline`中（上图中的pipeline和Stream是对于的），也就是说Pipeline包含一个数据源，0个或多个中间操作，1个结束操作。

举个例子：

```java
args = new String[]{"Accdv","Bscccccc"};
//创建数据源视图，为ReferencePipeline对象（Head)
Arrays.stream(args)
        .filter(s -> s.startsWith("A"))
        .mapToInt(String::length)
        .max().ifPresent(System.out::println);

```

`ReferencePipeline`抽象类有3个子类，分别是Head，StatefulOp和StatelessOp。每一个该对象表示一个Stage，上面代码用stage表示为

![Stream_pipeline_example.png](https://github.com/CarpenterLee/JavaLambdaInternals/blob/master/Figures/Stream_pipeline_example.png?raw=true)

```java
//下面的三个构造器中的super都是ReferencePipeline，而ReferencePipeline构造器中的super为AbstractPipeline
//head类的构造器 
Head(Spliterator<?> source,
     int sourceFlags, boolean parallel) {
    //数据源
    super(source, sourceFlags, parallel);
}

//StatefulOp构造器
StatefulOp(AbstractPipeline<?, E_IN, ?> upstream,
           StreamShape inputShape,
           int opFlags) {
    //upstream,当前stage的前一个stage
    super(upstream, opFlags);
    assert upstream.getOutputShape() == inputShape;
}

//StatelessOp构造器
StatelessOp(AbstractPipeline<?, E_IN, ?> upstream,
            StreamShape inputShape,
            int opFlags) {
    //upstream,当前stage的前一个stage
    super(upstream, opFlags);
    assert upstream.getOutputShape() == inputShape;
}

//在AbstractPipeline的构造器中有个很重要的是构建双向链表
AbstractPipeline(AbstractPipeline<?, E_IN, ?> previousStage, int opFlags) {
    if (previousStage.linkedOrConsumed)
        throw new IllegalStateException(MSG_STREAM_LINKED);
    previousStage.linkedOrConsumed = true;
    //这里很关键，不能丢了
    previousStage.nextStage = this;

    this.previousStage = previousStage;
    this.sourceOrOpFlags = opFlags & StreamOpFlag.OP_MASK;
    this.combinedFlags = StreamOpFlag.combineOpFlags(opFlags, previousStage.combinedFlags);
    this.sourceStage = previousStage.sourceStage;
    if (opIsStateful())
        sourceStage.sourceAnyStateful = true;
    this.depth = previousStage.depth + 1;
}
```

上面的这些stage双向链表构成了流水线，而每个stage所执行的操作保存在Sink类当中。在使用Stream中有个非常重要的问题即如果解决多次迭代问题和过多的中间值，如下：

```java
int longest = 0;
for(String str : strings){
    if(str.startsWith("A")){// 1. filter(), 保留以A开头的字符串
        int len = str.length();// 2. mapToInt(), 转换成长度
        longest = Math.max(len, longest);// 3. max(), 保留最长的长度
    }
}

//就以上代码在stream的sink中是如何实现的
//filter()
public void accept(P_OUT u) {
    //if条件成立执行下面的sink
    if (predicate.test(u))
        downstream.accept(u);
}
//mapToInt()
public void accept(P_OUT u) {
    //转换成int传给下个sink
    downstream.accept(mapper.applyAsInt(u));
}
//return int ReducingSink类返回OptionalInt，其get方法返回值保存在内state属性中
public void accept(int t) {
    if (empty) {
        empty = false;
        state = t;
    }
    else {
        state = operator.applyAsInt(state, t);
    }
}
```

这样的代码我们只使用了一次迭代，那么如果使用stream，那它是怎么避免多次迭代的呢？在Sink中保存的具体OP

| 方法名                          | 作用                                                         |
| ------------------------------- | ------------------------------------------------------------ |
| void begin(long size)           | 开始遍历元素之前调用该方法，通知Sink做好准备。               |
| void end()                      | 所有元素遍历完成之后调用，通知Sink没有更多的元素了。         |
| boolean cancellationRequested() | 是否可以结束操作，可以让短路操作尽早结束。                   |
| void accept(T t)                | 遍历元素时调用，接受一个待处理元素，并对元素进行处理。Stage把自己包含的操作和回调方法封装到该方法里，前一个Stage只需要调用当前Stage.accept(T t)方法就行了。 |

有了这几个方法就能很好的控制在OP过程中遇到的各种情况。对于有状态的操作，Sink的`begin()`和`end()`方法也是必须实现的。比如Stream.sorted()是一个有状态的中间操作，其对应的Sink.begin()方法可能创建一个乘放结果的容器，而accept()方法负责将元素添加到该容器，最后end()负责对容器进行排序。对于短路操作，`Sink.cancellationRequested()`也是必须实现的，比如Stream.findFirst()是短路操作，只要找到一个元素，cancellationRequested()就应该返回*true*，以便调用者尽快结束查找。Sink的四个接口方法常常相互协作，共同完成计算任务。**实际上Stream API各种OP操作内部实现的的本质，就是如何重载Sink的这四个接口方法**。

其实这种封装是对for循环迭代的模拟，在这个过程中，for循环内部每一步的操作封装为stage，在stage中具体干什么自己说了算。整个流水线组装完成之后的启动开关就是终止操作，以上面的max()方法为例，其内部会调用PipelineHelper的wrapAndCopyInto()，将当前的操作和从最后一个stage开始向上调用opWrapSink方法，而这个方法的返回值还是sink，也就是将statelessOp和statefulOp的opWrapSink返回的sink对象通过引用传递，形成责任链，链的开头就是head（head的opWrapSink不支持调用，毕竟是数据源）的下一个stage返回的sink。

```java
//wrapAndCopyInto()调用的方法
final <P_IN> Sink<P_IN> wrapSink(Sink<E_OUT> sink) {
    Objects.requireNonNull(sink);
	//形成引用调用链
    for ( @SuppressWarnings("rawtypes") AbstractPipeline p=AbstractPipeline.this; p.depth > 0; p=p.previousStage) {
        sink = p.opWrapSink(p.previousStage.combinedFlags, sink);
    }
    return (Sink<P_IN>) sink;
}

//AbstractPipeline中的方法
abstract Sink<E_IN> opWrapSink(int flags, Sink<E_OUT> sink);

//AbstractPipeline 第一种调用方式
final <P_IN> void copyInto(Sink<P_IN> wrappedSink, Spliterator<P_IN> spliterator) {
    Objects.requireNonNull(wrappedSink);

    if (!StreamOpFlag.SHORT_CIRCUIT.isKnown(getStreamAndOpFlags())) {
        wrappedSink.begin(spliterator.getExactSizeIfKnown());
        //spliterator其实和迭代器很像，在迭代的过程中不断的调动wrappedSink的accept方法
        spliterator.forEachRemaining(wrappedSink);
        wrappedSink.end();
    }
    else {
        copyIntoWithCancel(wrappedSink, spliterator);
    }
}
//SizedRefSortingSink 是Stream的sort方法封装的sink
private static final class SizedRefSortingSink<T> extends AbstractRefSortingSink<T> {
    private T[] array;
    private int offset;

    SizedRefSortingSink(Sink<? super T> sink, Comparator<? super T> comparator) {
        super(sink, comparator);
    }

    @Override
    @SuppressWarnings("unchecked")
    public void begin(long size) {
        if (size >= Nodes.MAX_ARRAY_SIZE)
            throw new IllegalArgumentException(Nodes.BAD_SIZE);
        array = (T[]) new Object[(int) size];
    }

    @Override
    public void end() {
        Arrays.sort(array, 0, offset, comparator);
        //在这里的中间操作，有状态的操作，自定义了临时容器，进行后面的中间操作
        downstream.begin(offset);
        if (!cancellationWasRequested) {
            for (int i = 0; i < offset; i++)
                downstream.accept(array[i]);
        }
        else {
            for (int i = 0; i < offset && !downstream.cancellationRequested(); i++)
                downstream.accept(array[i]);
        }
        downstream.end();
        array = null;
    }

    @Override
    public void accept(T t) {
        array[offset++] = t;
    }
}
```

总结下：

stream将所有的操作（分为中间操作，终止操作）封装为stage（包括三种类型head，statelessOp，statefulOp）形成双向链表，在终止操作中会遍历链表形成Sink引用调用链，然后执行引用链（head的下一个stage返回的sink），jdk提供的所以stream方法都是对sink（ChainedReference）类的重载。

## UrlConnection

`represent a communications link between the application and a URL`，这是一个抽象类，其子类有很多，如：JarUrlConnection,HttpUrlConnection,FtpUrlConnection等等。

常见的使用方式：

```java
URL realUrl = new URL("http://www.baidu.com");
//这里的open只是创建了URLConnection对象，并没有执行连接操作
URLConnection conn = realUrl.openConnection();
conn.setRequestProperty("accept", "*/*");
conn.setRequestProperty("connection", "Keep-Alive");
conn.setRequestProperty("user-agent", "Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1)");
//建立实际的连接
conn.connect();
```

上面的openConnection()会根据协议头调用对应的URLStreamHandler.openConnection()返回相应的URLConnection，Url内部维护一个table（协议--》URLStreamHandler），jdk实现的所有协议都在`sun.net.www.protocol`这个包下面，当获取协议的时候回通过反射创建，当然jdk也提供了方法实现自定义的URLStreamHandler，调用Url.setURLStreamHandlerFactory()添加一个协议工厂即可，但是只能设置一个工厂（但是工厂内部可以实现不同的协议呀）。

这里不详细描述各种协议的实现，UrlConnection相当于是一个协议框架，各种协议的实现都基于此。

## Buffer

抽象类buffer，源自jdk1.4版本，主要用于缓存基本类型数据（byte,short,int,float,double,long,char,boolean没有），该类描述了buffer操作的基本方法。

buffer的几个概念：

1. limit：当前buffer的大小
2. position：当前index的位置
3. capacity：数组的大小

有点迷糊的地方就是limit和capacity，其实很好理解，因为从buffer中可以切一段作为一个新的buffer，这一段新buffer其内部数组就有开始和结束，这里的结束就是limit。

buffer的创建由xxBuffer类的静态方法allocate和allocateDirect创建，xx即上面说的基本类型，下面以ByteBuffer为例看看代码

```java
//创建buffer，堆缓存
public static ByteBuffer allocate(int capacity) {
    if (capacity < 0)
        throw new IllegalArgumentException();
    //该列的HeapByteBufferR子类表示只读
    return new HeapByteBuffer(capacity, capacity);
}
//创建buffer，直接缓存
public static ByteBuffer allocateDirect(int capacity) {
    //该列的DirectByteBufferR子类表示只读
    return new DirectByteBuffer(capacity);
}
//HeapByteBuffer,该类的所有方法都较为简单就不展开，注意一旦所有返回buffer的方法都不会拷贝原有的数组，只是修改了比较位，所以性能很好
//构造器
HeapByteBuffer(int cap, int lim) {            // package-private
    //mark
    //position
    //limit
    //capacity
    //堆数组
    //offset
    super(-1, 0, lim, cap, new byte[cap], 0);
}
//DirectByteBuffer构造器，所有涉及unsafe的操作都是native方法
DirectByteBuffer(int cap) {                   // package-private
    super(-1, 0, cap, cap);//这个没什么好说的
    //判断是否需要对堆外内存进行对齐
    boolean pa = VM.isDirectMemoryPageAligned();
    int ps = Bits.pageSize();
    //需要对齐的话，就在cap+页大小
    long size = Math.max(1L, (long)cap + (pa ? ps : 0));
    //记录当前jvm直接内存使用量，只记录，size表示申请的大小，而cap表示使用的大小
    Bits.reserveMemory(size, cap);

    long base = 0;
    try {
        //申请内存
        base = unsafe.allocateMemory(size);
    } catch (OutOfMemoryError x) {
        Bits.unreserveMemory(size, cap);
        throw x;
    }
    //初始化内存，防止之前遗留的垃圾数据
    unsafe.setMemory(base, size, (byte) 0);
    if (pa && (base % ps != 0)) {
        // Round up to page boundary
        //地址裁剪，为了对齐内存页，对齐的主要目的是在CPU加载内存数据的时候按页加载
        //(base & (ps - 1))计算超过页的大小，举个例子看的明白些
        address = base + ps - (base & (ps - 1));
    } else {
        address = base;
    }
    //对外内存回收线程，不适用finalize()，这个坑太多，
    //回收的时机是没有该buffer引用时由Reference Handler线程调用clean方法，看下面的补充部分
    cleaner = Cleaner.create(this, new Deallocator(base, size, cap));
    att = null;
}

//cleaner的运行机制参考下面，这里主要看下其run方法
public void run() {
    if (address == 0) {
        // Paranoia
        return;
    }
    //释放内存
    unsafe.freeMemory(address);
    address = 0;
    //修改记录数
    Bits.unreserveMemory(size, capacity);
}
//其他方法不说了
```

## FileChannel

一个操作文件的类，理解为通道。

创建方式`FileChannelImpl.open()`，但是一般不会这么使用，一般会通过fileStream（FileInputStream.getChannel(), FileOutputStream.getChannel(), RandomAccessFile.getChannel()）的方式创建。open方法就是创建一个FileChannelImpl对象，该对象中保存有对应的流的是否可读、追加、文件描述符等属性。

write和read方法都需要设置ByteBuffer参数（参考上面的Buffer），代码如下：

```java
public int write(ByteBuffer src) throws IOException {
    ensureOpen();//通过内部属性判断状态
    if (!writable)
        throw new NonWritableChannelException();
    //object 锁
    synchronized (positionLock) {
        if (direct)
            Util.checkChannelPositionAligned(position(), alignment);
        int n = 0;
        int ti = -1;
        try {
            begin();
            ti = threads.add();
            if (!isOpen())
                return 0;
            do {
                n = IOUtil.write(fd, src, -1, direct, alignment, nd);
            } while ((n == IOStatus.INTERRUPTED) && isOpen());
            return IOStatus.normalize(n);
        } finally {
            threads.remove(ti);
            end(n > 0);//释放注册的回调
            assert IOStatus.check(n);
        }
    }
}
//父类AbstractInterruptibleChannel的方法，在当前线程上注册一个interrupt回调
protected final void begin() {
    if (interruptor == null) {
        //当出现中断时，关闭底层IO流
        interruptor = new Interruptible() {
            public void interrupt(Thread target) {
                synchronized (closeLock) {
                    if (closed)
                        return;
                    closed = true;
                    interrupted = target;
                    try {//close的逻辑就不看了，挺简单
                        AbstractInterruptibleChannel.this.implCloseChannel();
                    } catch (IOException x) { }
                }
            }};
    }
    //获取当前线程，将interruptor设置到其中。如果当前线程被调用了interrupt()
    blockedOn(interruptor);
    Thread me = Thread.currentThread();
    //做一个检查
    if (me.isInterrupted())
        interruptor.interrupt(me);
}
//Thread的中断
public void interrupt() {
        if (this != Thread.currentThread())
            checkAccess();

        synchronized (blockerLock) {
            Interruptible b = blocker;
            if (b != null) {
                //natvie方法
                interrupt0();           // Just to set the interrupt flag
                b.interrupt(this);//java内部的回调
                return;
            }
        }
        interrupt0();
}

//文件锁，对文件的部分进行加锁，shared表示是否为共享锁，只针对同一个JVM才有用（进程）
//FileInputStream共享锁，FileOutputStream排它锁
public FileLock lock(long position, long size, boolean shared){
    //...
    //校验部分，共享锁即读锁，排它锁即写锁
    if (shared && !readable)
    	throw new NonReadableChannelException();
	if (!shared && !writable)
    	throw new NonWritableChannelException();
    //使用锁表记录文件锁
    FileLockImpl fli = new FileLockImpl(this, position, size, shared);
    FileLockTable flt = fileLockTable();
    flt.add(fli);
}

private FileLockTable fileLockTable() throws IOException {
    if (fileLockTable == null) {
        synchronized (this) {
            if (fileLockTable == null) {
                if (isSharedFileLockTable()) {
                    int ti = threads.add();
                    try {
                        ensureOpen();
                        fileLockTable = FileLockTable.newSharedFileLockTable(this, fd);
                    } finally {
                        threads.remove(ti);
                    }
                } else {
                    fileLockTable = new SimpleFileLockTable();
                }
            }
        }
    }
    return fileLockTable;
}

```

关于write方法并发网引用的原文是有问题的，`因为无法保证write()方法一次能向FileChannel写入多少字节，因此需要重复调用write()方法，直到Buffer中已经没有尚未写入通道的字节`，就其举的例子来说是能保证的，就FileChannel的write而言是可以保证的。

## ReentrantLock

可重入锁（可重入表示能够让当前线程多次的进行对锁的获取操作），内部所有方法的实现基本都 依赖于Sync类，其子类包括NonfairSync和FairSync，这里的公平指的是如果在绝对时间上，先对锁进行获取的请求一定被先满足，那么这个锁是公平的，反之，是不公平的，也就是说等待时间最长的线程最有机会获取锁，也可以说锁的获取是有序的。公平锁效率较低，其优点是能够减少“饥饿”发生的概率，等待越久的请求越是能够得到优先满足。





# 补充

## 堆

堆的定义：

1. 给定堆中任意节点 P 和 C，若 P 是 C 的母节点，那么 P 的值会小于等于（或大于等于） C 的值
2. 若母节点的值恒**小于等于**子节点的值，此堆称为**最小堆（英语：min heap）**；反之，若母节点的值恒**大于等于**子节点的值，此堆称为**最大堆（英语：max heap）**。在堆中最顶端的那一个节点，称作**根节点**，根节点本身没有**母节点**
3. 堆总是一棵[完全树](https://zh.wikipedia.org/wiki/%E5%AE%8C%E5%85%A8%E4%BA%8C%E5%8F%89%E6%A0%91)。即除了最底层，其他层的节点都被元素填满，且最底层尽可能地从左到右填入。

若设二叉树的深度为h，除第 h 层外，其它各层 (1～h-1) 的结点数都达到最大个数，第 h 层所有的结点都连续集中在最左边，这就是完全二叉树。

堆的性质：

1. leftNo = parentNo*2+1

2. rightNo = parentNo*2+2

3. parentNo = (nodeNo-1)/2

堆数据结构主要用于解决在动态变化的数据集合中，求最大值或最小值问题，例如优先级队列PriorityQueue。

```java
public class PriorityQueue<E> extends AbstractQueue<E>
    implements java.io.Serializable {
   
    // 最小堆，所以要上移
    public boolean offer(E e) {
        if (e == null)
            throw new NullPointerException();
        modCount++;
        int i = size;
        if (i >= queue.length)
            grow(i + 1);
        size = i + 1;
        if (i == 0)
            queue[0] = e;
        else
            siftUp(i, e);
        return true;
    }


    @SuppressWarnings("unchecked")
    public E poll() {
        if (size == 0)
            return null;
        int s = --size;
        modCount++;
        E result = (E) queue[0];
        E x = (E) queue[s];
        queue[s] = null;
        if (s != 0)
       		// 要删除头部的节点，所以要下移
            siftDown(0, x);
        return result;
    }

  
    @SuppressWarnings("unchecked")
    private E removeAt(int i) {
        // assert i >= 0 && i < size;
        modCount++;
        int s = --size;
        if (s == i) // removed last element
            queue[i] = null;
        else {
            E moved = (E) queue[s];
            queue[s] = null;
            siftDown(i, moved);
            if (queue[i] == moved) {
                siftUp(i, moved);
                if (queue[i] != moved)
                    return moved;
            }
        }
        return null;
    }


    private void siftUp(int k, E x) {
    	// 这两种实质是一样的
        if (comparator != null)
            siftUpUsingComparator(k, x);
        else
            siftUpComparable(k, x);
    }

	// 理解这个图，下面的代码就能理解了
	// https://github.com/CarpenterLee/JCFInternals/blob/master/PNGFigures/PriorityQueue_offer.png
    @SuppressWarnings("unchecked")
    private void siftUpComparable(int k, E x) {
        Comparable<? super E> key = (Comparable<? super E>) x;
        while (k > 0) {
            int parent = (k - 1) >>> 1;
            Object e = queue[parent];
            if (key.compareTo((E) e) >= 0)
                break;
            queue[k] = e;
            k = parent;
        }
        queue[k] = key;
    }

	// 较大的值下沉
    private void siftDown(int k, E x) {
        if (comparator != null)
            siftDownUsingComparator(k, x);
        else
            siftDownComparable(k, x);
    }

    @SuppressWarnings("unchecked")
    private void siftDownComparable(int k, E x) {
        Comparable<? super E> key = (Comparable<? super E>)x;
        int half = size >>> 1;        // loop while a non-leaf
        while (k < half) {
            int child = (k << 1) + 1; // assume left child is least
            Object c = queue[child];
            int right = child + 1;
            //比较2个子节点，找到最小的那个
            if (right < size &&
                ((Comparable<? super E>) c).compareTo((E) queue[right]) > 0)
                c = queue[child = right];
           	// 然后判断这个最小值和当前前比较，核心思想是将两个字节点上移
            if (key.compareTo((E) c) <= 0)
                break;
            queue[k] = c;
            k = child;
        }
        queue[k] = key;
    }
    
	// 堆化整个数组
    private void heapify() {
        for (int i = (size >>> 1) - 1; i >= 0; i--)
            siftDown(i, (E) queue[i]);
    }
  
}
```

## Leader-Follower算法

这里需要解释下，对于线程池来说，其内部线程的管理是需要消耗资源的，在JDK1.4中引入的NIO编程模型，其采用Reactor模型（或者称为观察者模式），需要一个线程处理接受到的事件，然后交由其他work线程去处理，这里就会涉及到线程的上下文切花，包括数据拷贝，这对性能有一定的影响，尤其是当上下文切换很频繁的时候。

而该算法的基本思想是，将线程分为3种，leader、follower、processer（干活的），基本原则是同一时间只有一个leader，所以follower都在等待称为leader。线程池在启动的时候启动一个leader，等待事件，当接受到事件，leader线程首先会通知一个follower线程将其提拔为leader线程，然后自己称为processer线程处理任务，处理完成之后称为follower线程等待下次称为leader线程，这种方法消除了线程切换和数据交换带来的性能损失。



## 树

| 树名称              | 特点                                                         | 主要应用         | 备注                                                         |
| ------------------- | ------------------------------------------------------------ | ---------------- | ------------------------------------------------------------ |
| 平衡二叉树（AVL树） | 其利用二分查找的思想组装的树型结构（本身是二叉搜索树）；查询性能和树的高度成反比，所以为了减小树的高度出现了很多算法，如AVl，Treap，红黑树，平衡树，平衡二叉树左右两边树的高度相差不会大于1（没有相等重复的节点） |                  | 二分查找时间复杂度log(n)                                     |
| B树                 | （多路平衡二叉树）和平衡树不同点在于其叶子不止有2个节点，用于存储排序后数据，所以对于数据库来说不仅需要考虑查询的性能还需要考虑磁盘IO的性能，IO次数和树的高度有关，树的子节点最多个数k，则称k为B树的阶，k的大小通常由磁盘页大小决定的<br />B树的特点这里不罗列了。 | 数据库，文件系统 | 3阶b树，最多有3个子节点，节点最多有2个元素                   |
| B+树                | 该树比B树由更好的性能且方便范围查找，同样以3阶B+树<br />1. 所有的中间节点元素都同时存在于子节点，在子节点元素中是最大（或最小）元素<br />2. 所有的叶子结点中包含了全部元素的信息，及指向含这些元素记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接（实际的数据存放在叶子节点中）<br />3. 有k个子树的中间节点包含有k个元素（B树中是k-1个元素），每个元素不保存数据，只用来索引，所有数据都保存在叶子节点 | 数据库，文件系统 | 叶子节点之间使用链表连接（方便范围查找）                     |
| Trie树              | 字典树（前缀树）                                             |                  |                                                              |
| 红黑树              | 自平衡的二叉搜索树，额外的特点包括：<br />1. 节点是红色或黑色<br />2. 根节点是黑色<br />3.  所有叶子节点都是黑色的（最后一层的空节点）<br />4. 每个红色节点必须有两个黑色的子节点（从每个叶子到根的所有路径上不能有两个连续的红色节点）<br />5. 相比AVL树，红黑树牺牲了部分平衡性以换取在插入和删除时少量的旋转次数，整体来说性能高于AVL树<br />6. 从任一节点到其每个叶子的所有[简单路径](https://zh.wikipedia.org/wiki/%E9%81%93%E8%B7%AF_(%E5%9B%BE%E8%AE%BA))都包含相同数目的黑色节点 |                  | 所有的约束条件保证了：从根到叶子的最长的可能路径不多于最短的可能路径的两倍长 |
| 二叉搜索树          | 1. **左**子树上所有结点的值均**小于或等于**它的根结点的值。<br />2. **右**子树上所有结点的值均**大于或等于**它的根结点的值。<br />3. 左、右子树也分别为二叉排序树。（比较的算法自己定，比如hash值） |                  |                                                              |



## Cuckoo hash 

该hash算法主要用于解决hash冲突，即使使用简单的hash函数就能实现key的均匀分布。

Dense Hash：使用线性探测解决hash冲突（collision），即当出现冲突的hash时，向后遍历找到没有值的空位插进去，性能很糟糕

Chain Hash Table：使用拉链法解决hash冲突，空间利用率较高，但是由于使用的是链表所以查询性能一般，HashMap就是用的这个

其主要思想是计算hash的时候有2个hash函数，一个是主位置，一个备用位置，当主位置上出现碰撞时，使用不用位置，如果备用出现碰撞，则将备用位置的value踢出，将想要放的值放入，重复这个过程，直到没有冲突为止。

这里需要完善。

## Spliterator

java8新添加的可分割的迭代器，为stream并发遍历数据源执行而生的，原先java的iterator只能够顺序遍历。

| 方法名称 | 方法描述 | 备注 |
| ------------------------------------------------- | ---- | ---- |
| boolean tryAdvance(Consumer<? super T> action) | 有元素的话执行动作返回true，否则false | |
| void forEachRemaining(Consumer<? super T> action) | 循环调用tryAdvance() |      |
| Spliterator<T> trySplit()                         | 对数据源进行分割，形成更小的数据源 |      |
| long estimateSize()                               | 估计剩余需要遍历的元素 |      |
| long getExactSizeIfKnown()                        | 试着获取实际大小，没有的或就估计 |      |
| int characteristics()                             | 特征类型 | 这个特征用于优化循环 |

```java
static final class ArrayListSpliterator<E> implements Spliterator<E> {

   
    private final ArrayList<E> list;
    //开始位置
    private int index; // current index, modified on advance/split
    //结束位置
    private int fence; // -1 until used; then one past last index
    //不支持并发修改，所以做一个标记，每一次对ArrayList的修改都会是该值+1
    private int expectedModCount; // initialized when fence set

    /** Create new spliterator covering the given  range */
    ArrayListSpliterator(ArrayList<E> list, int origin, int fence,
                         int expectedModCount) {
        this.list = list; // OK if null unless traversed
        this.index = origin;
        this.fence = fence;
        this.expectedModCount = expectedModCount;
    }
	//获取结束index ，很好理解
    private int getFence() { // initialize fence to size on first use
        int hi; // (a specialized variant appears in method forEach)
        ArrayList<E> lst;
        if ((hi = fence) < 0) {
            if ((lst = list) == null)
                hi = fence = 0;
            else {
                expectedModCount = lst.modCount;
                hi = fence = lst.size;
            }
        }
        return hi;
    }

    //对ArrayList进行切分，从中间切，注意这里的切分不会修改原来的list
    public ArrayListSpliterator<E> trySplit() {
        int hi = getFence(), lo = index, mid = (lo + hi) >>> 1;
        //新的ArrayListSpliterator范围是index到mid，原来的是mid到fence
        return (lo >= mid) ? null : // divide range in half unless too small
            new ArrayListSpliterator<E>(list, lo, index = mid,
                                        expectedModCount);
    }

    //访问下一个元素
    public boolean tryAdvance(Consumer<? super E> action) {
        if (action == null)
            throw new NullPointerException();
        int hi = getFence(), i = index;
        //判断是否越界
        if (i < hi) {
            index = i + 1;
            @SuppressWarnings("unchecked") E e = (E)list.elementData[i];
            action.accept(e);
            //检查list是否被修改过            
            if (list.modCount != expectedModCount)
                throw new ConcurrentModificationException();
            return true;
        }
        return false;
    }
	//遍历剩余的元素
    public void forEachRemaining(Consumer<? super E> action) {
        int i, hi, mc; // hoist accesses and checks from loop
        ArrayList<E> lst; Object[] a;
        if (action == null)
            throw new NullPointerException();
        if ((lst = list) != null && (a = lst.elementData) != null) {
            //未初始化
            //下面的循环开始前，记录当前的mc
            if ((hi = fence) < 0) {
                mc = lst.modCount;
                hi = lst.size;
            }
            else
                mc = expectedModCount;
            if ((i = index) >= 0 && (index = hi) <= a.length) {
                for (; i < hi; ++i) {
                    @SuppressWarnings("unchecked") E e = (E) a[i];
                    action.accept(e);
                }
                //校验mc，是在遍历之后，而不是在for循环中每次都校验
                if (lst.modCount == mc)
                    return;
            }
        }
        throw new ConcurrentModificationException();
    }
	//返回数组大小
    public long estimateSize() {
        return (long) (getFence() - index);
    }
	//设置该list的特性
    public int characteristics() {
        return Spliterator.ORDERED | Spliterator.SIZED | Spliterator.SUBSIZED;
    }
}
```

对于不同的集合java都内置了其对于的Spliterator，所以我们在直接使用的时候不需要考虑这些，但是如果是自定义的集合类就需要考虑了，例如guava中的集合类基本都有实现对于的Spilterator（CollectSpliterators类中）。

## Cleaner&Finalizer

Cleaner在jdk9之后正式取代Object.finalize()，但是请注意这个cleaner的使用还是有坑的，只是相对于finalize方法稍微少点。Finalizer机制是不可预知的，往往是危险的，而且通常是不必要的。 它们的使用会导致不稳定的行为，糟糕的性能和移植性问题， Cleaner机制不如Finalizer机制那样危险，但仍然是不可预测，运行缓慢并且通常是不必要的

在开始之前需要回顾下Reference（也是一个抽象类），也就是引用体系，最常见的是强引用StrongReference（new Object()创建），除此之外还有PhantomReference、WeakReference、SoftReference、FinalReference（为实现finalization），JVM在进行GC会根据对象不同的引用类型进行不同的处理。

1. SoftReference：内存空间足够，垃圾回收器就不会回收它；如果内存空间不足了，就会回收这些对象的内存

2. WeakReference：在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存

3. PhantomReference：“虚引用”顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收

首先finalize方法调用方式。当我们创建对象的时候如果对象重写了finalize方法，会创建（由JVM调用Finalizer.register()）一个对应的FinalReference（也就是Finalizer类，自己创建一个对象重写finalize方法，通过idea的memory分析能够确认这点），同时在reference类中静态代码块会创建`Reference Handler`线程（最高优先级，daemon线程，while（true）运行），GC会将可以被回收的finalizer对象，赋值到Reference.pending属性中，然后由该线程添加到Finalizer的全局队列中，*同时如果对象是Cleaner类型，会运行其clean()*。

在Finalizer被创建的时候，其会启动Finalizer线程（daemon，while（true），优先级低于`Reference Handler`线程）用于调用队列中对象的finalize方法。

对于Cleaner(1.9版本以下)，代码很简单，内部使用双向链表（保证存在引用，在没有被执行clean方法前防止被再次gc），在9版本中，之前的版本处理方法依然保留，也就是上面的Cleaner，但是在java.lang.ref中也加了一个cleaner，该类主要用于替代finalize方法。

1. 每创建一个cleaner在其内部都会创建一个新的线程，但是每个cleaner可以注册多个要清理的活动（内部还是双向链表）
2. 清理任务中不能执行长时间的任务
3. 注册的清理任务不能保证会被执行，也不知何时被执行

总的来说这两个东西在业务中都不应该使用。

## 自旋锁（Spinlock）

自旋锁和互斥锁目的都为保证同一时刻只有一个线程能访问资源，但是互斥锁性能消耗很大。自旋锁对于申请资源的线程不会休眠而是循环等待锁被释放。

但是循环等待会带来两个问题：

1. 死锁：在递归调用中很容易出现这个问题，第一次调用获取锁，第二次调用就无法执行，也就出现死锁了
2. 占用cpu资源过多：可以使用计数器，限定循环次数

自旋锁适用的场景主要为锁持有时间较短的情况



