---
title: "深度学习简介"
subtitle: "TensorFlow：实战Google深度学习框架「01」"
layout: post
author: "echisenyang"
header-style: text
hidden: true
catalog: true
tags:
  - TensorFlow
---



## 深度学习简介

### 人工智能、机器学习与深度学习

<img src="https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/TbK32A.png" alt="TbK32A" style="zoom: 33%;" />

然而，**对许多机器学习问题来说，特征提取不是一件简单的事情** (*让我想起了天池二手车价格预测大赛，建特征真的是。。。*)。在一些复杂问题上，要通过人工的方式设计有效的特征集合，需要很多的时间和精力，有时甚至需要整个领域数十年的研究投入。

既然人工的方式无法很好地抽取实体中的特征，那么是否有自动的方式呢？答案是肯定的。**深度学习解决的核心问题之一就是自动地将简单的特征组合成更加复杂的特征**，并使用这些组合特征解决问题。深度学习是机器学习的一个分支，它除了可以学习特征和任务之间的关联，还能自动从简单特征中提取更加复杂的特征。

<img src="https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/uM5Z1p.png" alt="uM5Z1p" style="zoom: 33%;" />

### 深度学习的发展历程

第一个阶段：McCulloch-Pitts Neuron 结构和感知机模型

- 有很大的局限性：感知机模型只能解决线性可分问题，在当时的计算能力下， 实现多层的神经网络是不可能的事情。”基于感知机的研究注定将失败”，这导致了神经网络的第一次重大低潮期，在之后的十多年内，基于神经网络的研究几乎处于停滞状态。

第二个阶段：80年代分布式知识表达（distributed representation ）和神经网络反向传播算法

<img src="https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/us2ojM.png" alt="us2ojM" style="zoom: 33%;" />

- 局限性依然存在：然而，在神经网络发展的同时，传统的机器学习算法也有了突破性的进展，并在90年代末逐步超越了神经网络，成为当时机器学习领域最常用的方法。虽然训练神经网络的算法得到了改进，但在当时的计算资源下，要训练深层的神经网络仍然是非常困难的。其次，当时的数据量比较小，无法满足训练深层神经网络的需求。

第三个阶段：近十年，计算机性能的进一步提高，以及云计算、GPU的出现，计算量已经不再是阻碍神经网络发展的问题。与此同时，随着互联网＋的发展，获取海量数据也不再困难。

<img src="https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/zVg0eV.png" alt="zVg0eV" style="zoom: 33%;" />

### 深度学习的应用

- 计算机视觉：AlexNet、ImageNet、MNIST
- 语音识别：深度学习的语音识别模型
- 自然语言处理：语言模型（language modeling）、机器翻译、词性标注（part-of-speech tagging）、实体识别(named entity recognition,NER）、情感分析（sentiment analysis）

> 说实话：现在比较高效的一些模型，诸如lstm，应该也都是收到了cv领域AlexNet之后，块状模块的影响，形成nlp领域自己的lstm块，或者lstm层

- 人机博弈：深蓝、AlphaGo、《星际争霸 2》



