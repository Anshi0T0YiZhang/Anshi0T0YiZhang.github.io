---
layout:     post
title:      "Hadoop"
subtitle:   " \"好好学习，天天向上\""
date:       2019-06-11 00:00:00
author:     "WQ"
header-img: "img/blogImg/2019-06-11-2.jpg"
catalog: true
tags:
    - Hadoop
---

## Hadoop

零碎的笔记，还未整理

注意mr的实现，基于标准sql，所以在此之前需要学习标准sql语法

join：
在数据库中join的实现，join的算法选择主要由当前的优化模式、表大小、连接列是否有索引、连接列是否有排序

1. sort merge join：首先对两个关联表进行排序，这时对两表进行循环，具体参考tez的examples中的SortMergeJoinExample。但是该算法的性能大于hash join，只有在表已经时排好序的情况下才好于hash join。
1. hash join：对较小的表将join key作为hash key，数据放入hashmap中，然后扫描较大的表进行join。如果hash表过大，则分成若干个partition写入文件。这个方式适用于较小的表内放入内存当中。
1. nested-loop join：简单嵌套循环连接，双层for循环，时间复杂度n*m，m表需要做n次全表扫描。
1. indexed nested-loop join：索引嵌套循环连接，当由表的匹配条件为索引字段时会触发这种join，可以极大的降低扫描表的次数。
1. blocked nested-loop join：缓存嵌套内循环（当不是indexed join时，mysql默认使用这种join，可配置），一次缓存多个需要查询的外循环，减少实际查询时，n*m中n的个数。



在MR中join的实现
1. map 端join：针对其中一个表数据量较小，能放到内存当中
1. reduce端join：在map端将两个表的join条件作为key，并加上表标识符，在reduce端将两个表的数据区分出来，按left，right，inner，进行输出
针对大于2个表的join，按照顺序进行join，产生中间表，然后和后面的表继续join

union

聚合函数

group up：将group的字段放到key当中进行比较


order by：将order的字段放到key当中进行比较，key中比较的顺序按照标准sql执行


Partition：分区，map的结果发送到哪个reduce当中

子查询：使用单独的MR处理输出作为外查询的输入表



YarnRunner启动MRAppMaster（以独立JVM进程的方式）



YarnChild接收到task（MapTask，ReduceTask），负责执行。而task的配置信息是在hdfs中以job.xml的形式保存。注意虽然YarnChild是独立的jvm进程，但是当执行完一个task之后就会结束不会重复利用



## HDFS

## Counters

在hadoop官网中关于counter的描述是用expensive来描述的。

在mapTask或reduceTask中使用TaskReporter进行周期上报状态，也就是在MRMaster中保留每个task的counter（在生命周期内），所以成本很高

## RPC

### Client

1. 处理ping的方式，是在read方法的SocketTimeoutException异常捕捉中进行的
2. 在创建Connection对象之后调用setupIOstreams方法建立连接并启动connection线程，用于异步接受返回数据
3. 数据的发送调用connection的sendRpcRequest，也是异步的

### Server

ConnectionManager：周期性的检查connection是否需要被关闭

Connection：入口方法readAndProcess，注意该方法会被持续调用（Reader类的doRunLoop方法），将读到的数据放到buffer中。processOneRpc用于处理缓存的数据（可以理解为一次rpc调用），将buffer数据组装成Call对象，保存到Server类的CallQueueManager属性中。

包含Listener，Responder，Handler三个主要类（在start方法中可以找到），这三个类都继承了Thread类。

Listener（单线程）：包含多个reader线程（reactor模型），这里的代码很值得学习，有很多细节需要留意，在

Listener中的selector关注accept事件，接受到请求后，将包装好的connection对象绑定到该key中，同时将connection分配到一个reader当中。

在reader当中，使用阻塞队列保存connection，这里会注册read事件，一旦有事件发生就调用相应的connection的readAndProcess方法

Responder（单线程）：使用pending作为是否该类运行的标记，如果不需要运行while true循环等待（wait()），关于pending的几个方法值得学习。这里的代码可能有点看不懂，需要结合handler来看

Handler（多个线程）：从server的callQueue中拿取请求，调用call方法，将返回值包方法call对象中，保存在队列中，因为同一个rpc可能会有多个调用

![reduce-fetch-merge](/img/blogImg/hadoop/hadoop-rpc-server.png)



### RPC

辅助类，编程调用的方法都封装在该类中



## CompressionCodec

包含compression和decompression，在CompressionCodecFactory中使用SPI注册（在SPI文件中能找到所以的算法实现），当然自己也可以通过该方式添加算法。CodecPool作为实例池是日常使用的基本类，默认的压缩算法是DefaultCodec即Zlib

同时每个压缩算法基本都提供了InputStream和OutputStream的包装类，方便用于对流数据的压缩和解压

## Serialization

使用SerializationFactory创建序列化类，默认有WritableSerialization，AvroSpecificSerialization，AvroReflectSerialization，当然还有java的序列化，不过是experimental，估计还是性能不行

WritableSerialization，其实就是调用自己定义的对象实现Writable接口中的方法

## FileSystem

## Hadoop ShutDown Mechanism

在将shutdown机制的时候，必须得先提下startUp机制。

通过hadoop的脚本可以发现，其启动和停止都是通过hadoop-functions.sh的脚本实现。

```shell
function hadoop_stop_daemon
{
  local cmd=$1
  local pidfile=$2
  shift 2

  local pid
  local cur_pid

  if [[ -f "${pidfile}" ]]; then
    pid=$(cat "$pidfile")

    kill "${pid}" >/dev/null 2>&1

    wait_process_to_die_or_timeout "${pid}" "${HADOOP_STOP_TIMEOUT}"

    if kill -0 "${pid}" > /dev/null 2>&1; then
      hadoop_error "WARNING: ${cmd} did not stop gracefully after ${HADOOP_STOP_TIMEOUT} seconds: Trying to kill with kill -9"
      kill -9 "${pid}" >/dev/null 2>&1
    fi
    wait_process_to_die_or_timeout "${pid}" "${HADOOP_STOP_TIMEOUT}"
    if ps -p "${pid}" > /dev/null 2>&1; then
      hadoop_error "ERROR: Unable to kill ${pid}"
    else
      cur_pid=$(cat "$pidfile")
      if [[ "${pid}" = "${cur_pid}" ]]; then
        rm -f "${pidfile}" >/dev/null 2>&1
      else
        hadoop_error "WARNING: pid has changed for ${cmd}, skip deleting pid file"
      fi
    fi
  fi
}
```

只限于通过ServiceLauncher启动的service，才使用下面的停止方式。

ShutdownHookManager：管理所有的钩子。在Main方法中会注册关闭时的钩子打印关闭时的提示信息。

SignalLogger：在signal中注册打印接受到的信号信息。

IrqHandler：用于接受信号，和上面的SignalLogger类似，存在SignalLogger的原因时又些情况下时没有注册IrqHandler的所以需要其作为替代。交给InterruptEscalator处理。

InterruptEscalator：接受到任何型号都作为stop的信号，此时会创建一个单独的线程将service关闭-stop(为何异步？)

service：生命周期接口

对于其他的service停止方式，是在其启动的时候直接注册钩子，在钩子当中调用service.stop()。

## MapReduce

### 关于Sort

在map和reduce阶段都存在，除了排序sort带来的好处，更多的在于在内部处理过程中使用并归对大数据处理。

##### map端（包含map和sort两个阶段）

sort在2.0版本之前不能关闭，之后可以关闭，因为这个排序时为reduce阶段准备的（方便merge，外排降低内存），所以如果没有reduce就没有map阶段的sort，若map的输出类（DirectMapOutputCollectorMapOutputBuffer）使用Direct的话也没有sort阶段。sort的算法默认使用QuickSort（还有HeapSort）。sort阶段在spill之后，溢写前（每个分区一个文件），最后对这些文件进行并归。

spill-map-sort-(combine)-(writeToFile)

##### reduce端（包含copy，sort，reduce三个阶段）

shuffle(copy-sort)--reduce

shuffle阶段由Shuffle类负责

代码中sort又被称为merge

![reduce-fetch-merge](/img/blogImg/hadoop/hadoop-shuffle-sort.jpg)

在上述的shuffle完成之后，回到shuffle的run，执行merge的close，进行finalMerge即内存数据和磁盘数据的merge，具体的代码逻辑就不加以罗列。

```
job.setSortComparatorClass():定义key的比较器，如果key重写了compareTo则这个可以忽略
job.setGroupingComparatorClass():在reduce阶段定义如何分组，即那些value放在一个key（通过分区定义的，所以可能不同）的values当中，在例如二次排序当中就必须定义该值。这里group的含义是reduce中不同的key值
```



### 问题

#### counter的限制

默认是120，在网上有很多关于修改限制的帖子，但是都没有用，因为这是hadoop的bug，具体可以参考[jira1](https://issues.apache.org/jira/browse/MAPREDUCE-6925)和[jira2](https://issues.apache.org/jira/browse/MAPREDUCE-5875)，我所遇到的异常的出处在mr任务执行完向MRAppMaster上报状态TaskStatus反序列化时进行了数量校验，所以需要在MRAppMaster的main方法中处调用`Limits.init(conf)`，缺少的地方可能还有别的，解决这个问题最简单的就是直接修改代码中默认的120后重新编译打包





## 小知识

### System.exit和Runtime halt区别

对应在Runtime代码中的exit() halt()，在其doc描述是：

1. exit在jvm shutdown时包含两个阶段，第一阶段调用注册的shutdown hooks，知道所有的钩子执行完成。第二阶段如果已启用runFinalizersOnExit设置为true，则运行所有未调用的终结方法（finalizer方法）。
2. halt就如doc所说的应该小心使用，不会执行exit的两个阶段而是直接退出。

hadoop许多的main方法在开始时就设置了当前现场的异常捕捉器UncaughtExceptionHandler，在OutOfMemoryError时才会使用halt()。