---
layout:     post
title:      "Hadoop"
subtitle:   " \"好好学习，天天向上\""
date:       2019-06-11 00:00:00
author:     "WQ"
header-img: "img/blogImg/2019-06-11-2.jpg"
catalog: true
tags:
    - Hadoop
---

## Hadoop

注意mr的实现，基于标准sql，所以在此之前需要学习标准sql语法

join：
在数据库中join的实现，join的算法选择主要由当前的优化模式、表大小、连接列是否有索引、连接列是否有排序

1. sort merge join：首先对两个关联表进行排序，这时对两表进行循环，具体参考tez的examples中的SortMergeJoinExample。但是该算法的性能大于hash join，只有在表已经时排好序的情况下才好于hash join。
1. hash join：对较小的表将join key作为hash key，数据放入hashmap中，然后扫描较大的表进行join。如果hash表过大，则分成若干个partition写入文件。这个方式适用于较小的表内放入内存当中。
1. nested-loop join：简单嵌套循环连接，双层for循环，时间复杂度n*m，m表需要做n次全表扫描。
1. indexed nested-loop join：索引嵌套循环连接，当由表的匹配条件为索引字段时会触发这种join，可以极大的降低扫描表的次数。
1. blocked nested-loop join：缓存嵌套内循环（当不是indexed join时，mysql默认使用这种join，可配置），一次缓存多个需要查询的外循环，减少实际查询时，n*m中n的个数。



在MR中join的实现
1. map 端join：针对其中一个表数据量较小，能放到内存当中
1. reduce端join：在map端将两个表的join条件作为key，并加上表标识符，在reduce端将两个表的数据区分出来，按left，right，inner，进行输出
针对大于2个表的join，按照顺序进行join，产生中间表，然后和后面的表继续join

union

聚合函数

group up：将group的字段放到key当中进行比较


order by：将order的字段放到key当中进行比较，key中比较的顺序按照标准sql执行


Partition：分区，map的结果发送到哪个reduce当中

子查询：使用单独的MR处理输出作为外查询的输入表



YarnRunner启动MRAppMaster（以独立JVM进程的方式）



YarnChild接收到task（MapTask，ReduceTask），负责执行。而task的配置信息是在hdfs中以job.xml的形式保存。注意虽然YarnChild是独立的jvm进程，但是当执行完一个task之后就会结束不会重复利用



## HDFS

## Counters

在hadoop官网中关于counter的描述是用expensive来描述的。

在mapTask或reduceTask中使用TaskReporter进行周期上报状态，也就是在MRMaster中保留每个task的counter（在生命周期内），所以成本很高

## RPC

### Client

1. 处理ping的方式，是在read方法的SocketTimeoutException异常捕捉中进行的
2. 在创建Connection对象之后调用setupIOstreams方法建立连接并启动connection线程，用于异步接受返回数据
3. 数据的发送调用connection的sendRpcRequest，也是异步的

### Server

ConnectionManager：周期性的检查connection是否需要被关闭

Connection：入口方法readAndProcess，注意该方法会被持续调用（Reader类的doRunLoop方法），将读到的数据放到buffer中。processOneRpc用于处理缓存的数据（可以理解为一次rpc调用），将buffer数据组装成Call对象，保存到Server类的CallQueueManager属性中。

包含Listener，Responder，Handler三个主要类（在start方法中可以找到），这三个类都继承了Thread类。

Listener（单线程）：包含多个reader线程（reactor模型），这里的代码很值得学习，有很多细节需要留意，在

Listener中的selector关注accept事件，接受到请求后，将包装好的connection对象绑定到该key中，同时将connection分配到一个reader当中。

在reader当中，使用阻塞队列保存connection，这里会注册read事件，一旦有事件发生就调用相应的connection的readAndProcess方法

Responder（单线程）：使用pending作为是否该类运行的标记，如果不需要运行while true循环等待（wait()），关于pending的几个方法值得学习。这里的代码可能有点看不懂，需要结合handler来看

Handler（多个线程）：从server的callQueue中拿取请求，调用call方法，将返回值包方法call对象中，保存在队列中，因为同一个rpc可能会有多个调用

![reduce-fetch-merge](/img/blogImg/hadoop/hadoop-rpc-server.png)







### RPC

辅助类，编程调用的方法都封装在该类中



## MapReduce

### 关于Sort

在map和reduce阶段都存在，除了排序sort带来的好处，更多的在于在内部处理过程中使用并归对大数据处理。

##### map端（包含map和sort两个阶段）

sort在2.0版本之前不能关闭，之后可以关闭，因为这个排序时为reduce阶段准备的（方便merge，外排降低内存），所以如果没有reduce就没有map阶段的sort，若map的输出类（DirectMapOutputCollectorMapOutputBuffer）使用Direct的话也没有sort阶段。sort的算法默认使用QuickSort（还有HeapSort）。sort阶段在spill之后，溢写前（每个分区一个文件），最后对这些文件进行并归。

spill-map-sort-(combine)-(writeToFile)

##### reduce端（包含copy，sort，reduce三个阶段）

shuffle(copy-sort)--reduce

shuffle阶段由Shuffle类负责

代码中sort又被称为merge

![reduce-fetch-merge](/img/blogImg/hadoop/hadoop-shuffle-sort.jpg)

在上述的shuffle完成之后，回到shuffle的run，执行merge的close，进行finalMerge即内存数据和磁盘数据的merge，具体的代码逻辑就不加以罗列。

```
job.setSortComparatorClass():定义key的比较器，如果key重写了compareTo则这个可以忽略
job.setGroupingComparatorClass():在reduce阶段定义如何分组，即那些value放在一个key（通过分区定义的，所以可能不同）的values当中，在例如二次排序当中就必须定义该值。这里group的含义是reduce中不同的key值
```



### 问题

1. Mapreduce的数据倾斜