---
layout:     post
title:      TIANCHI 阿里天池大赛 Rank 52 (TOP1.85%)
subtitle:   TIANCHI天池大赛
date:       2020-04-04
author:     Young
header-img: img/bg-post/1*EbpKczfURCvAF6uUp_Hhew.jpeg
catalog: true
tags:
    - tianchi

---

## TIANCHI 阿里天池大赛 Rank 52 (TOP1.85%)

官方证书

![2tp2Dz](https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/2tp2Dz.png)天池杯大赛结束啦，最终排名是 52/2815，有点可惜最后两次提交没能更进一步（线下406分数，可以排top10），据说还会收到天池官方给寄的小礼物，有点期待天池会给啥。。。

> 更新：前几名的礼物是 airpods pro还有新款的ipad，然后我收到的是小米充电宝（感谢阿里爸爸，hhh，不过怎么啥都送小米充电宝呢，想起来好像还有个字节跳动送的小米充电宝。。。） 

![x6If8A](https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/x6If8A.png)

![w95hus](https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/w95hus.png)

通过这次天池大赛，收获颇多，无论是对keras建模调参，还是数据分析，都有了更深刻的理解。放两张图，一张是实习公司提供的GPU资源，比赛这几天0号卡一直留给我用，挺感激的～

<img src="https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/XMHWPb.png" alt="XMHWPb" style="zoom: 50%;" />

第二张图是第一次尝试对NN进行ensemble，感觉这玩意真是个神器啊，感叹。。。

![qjT6VA](https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/qjT6VA.jpg)

心路历程都在之前的「天池比赛二手车价格预测」记录了，这里就不赘述了。下面附上参赛代码

```python
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow import keras
from sklearn.metrics import mean_absolute_error
from keras.models import Sequential
from keras.layers import Dense
from keras.callbacks import ModelCheckpoint
import matplotlib.pyplot as plt
from scipy.special import boxcox, inv_boxcox
from sklearn.model_selection import StratifiedKFold
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "0"


#########################################################################
# 1. 数据不完整预处理
data_train = pd.read_csv(r'/home/jiale/codes/AI_JOB_Notes/Datawhale/tianchi/used_car_train_20200313.csv',sep = ' ')
data_test = pd.read_csv(r'/home/jiale/codes/AI_JOB_Notes/Datawhale/tianchi/used_car_testA_20200313.csv',sep = ' ')
#获得y值
y = data_train['price'].values
y_boxcox = boxcox(y, 0.2)
#特征归一化
min_max_scaler = MinMaxScaler()
min_max_scaler.fit(data_train[tags].values)
x = min_max_scaler.transform(data_train[tags].values)
x_ = min_max_scaler.transform(data_test[tags].values)
#切分数据集
x_train,x_test,y_train,y_test = train_test_split(x,y_boxcox,test_size = 0.1)


#########################################################################
# 2. 定义模型
seed = 7
numpy.random.seed(seed)
kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)
cvtrain = []
cvtest = []
for i, (train_index, val_index) in enumerate(kfold.split(data_train[tags], data_train["price"])):
    x_train_kf, x_val_kf = x[train_index], x[val_index]
    y_train_kf, y_val_kf = y_boxcox[train_index], y_boxcox[val_index]
    
    model = keras.Sequential([
            # The Input Layer :
       		keras.layers.Dense(256,kernel_initializer='normal',
                          activation='relu',input_dim = x_train_kf.shape[1]), 
            # The Hidden Layers :
            # keras.layers.Dropout(0.1),
            keras.layers.Dense(128,kernel_initializer='normal',activation='relu'), 
            # keras.layers.Dropout(0.5),
            keras.layers.Dense(64,kernel_initializer='normal',activation='relu'), 
            # keras.layers.Dropout(0.2),
            # keras.layers.Dense(256,kernel_initializer='normal',activation='relu'), 
            # The Output Layer :
            keras.layers.Dense(1,kernel_initializer='normal',activation='linear')])
    model.compile(loss='mean_absolute_error', optimizer='adam', 
                  metrics=['mean_absolute_error'])
    model.summary()

    # checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' 
    checkpoint_name=str(i) + "weights_0409.net_256_128_64_1.validation.best.hdf5"
    checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')
    callbacks_list = [checkpoint]

	# Fit the model
    history = model.fit(x_train_kf, y_train_kf, validation_data=(x_val_kf,y_val_kf), epochs=2000, batch_size=1024,
    callbacks=callbacks_list)
    
    # evaluate the model
    print("train:",mean_absolute_error(inv_boxcox(y_train_kf, 0.2),inv_boxcox(model.predict(x_train_kf), 0.2)))
    print("test:",mean_absolute_error(inv_boxcox(y_val_kf, 0.2),inv_boxcox(model.predict(x_val_kf), 0.2)))
    cvtrain.append(mean_absolute_error(inv_boxcox(y_train_kf, 0.2),inv_boxcox(model.predict(x_train_kf), 0.2)))
    cvtest.append(mean_absolute_error(inv_boxcox(y_val_kf, 0.2),inv_boxcox(model.predict(x_val_kf), 0.2)))
    
#     scores = model.evaluate(X[test], Y[test], verbose=0)
#     print("%s: %.2f%%" % (model.metrics_names[1], scores[1]*100))
#     cvscores.append(scores[1] * 100)
print("%.2f%% (+/- %.2f%%)" % (numpy.mean(cvtrain), numpy.mean(cvtest)))


#########################################################################
# 3. 评估结果
wights_file = "0weights_0409.net_256_128_64_1.validation.best_432.hdf5" 
# choose the best checkpoint 
model.load_weights(wights_file) # load it
model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])
print(i)
print(mean_absolute_error(inv_boxcox(y_train, 0.2),inv_boxcox(model.predict(x_train), 0.2)))
print(mean_absolute_error(inv_boxcox(y_test, 0.2),inv_boxcox(model.predict(x_test), 0.2)))
#输出结果预测
res.append(inv_boxcox(model.predict(x_), 0.2))


#########################################################################
# 4.输出结果预测
data_test_price = pd.DataFrame(finalres,columns = ['price'])
results = pd.concat([data_test['SaleID'],data_test_price],axis = 1)
results.head()
results.to_csv('results0410_stacking.csv',sep = ',',index = None)
```

