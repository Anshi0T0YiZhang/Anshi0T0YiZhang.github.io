---
title: "「白板推导笔记」22-23"
subtitle: "Machine Learning Session"
layout: post
author: "echisenyang"
header-style: text
hidden: true
catalog: true
tags:
  - 笔记
  - 白板推导笔记
---



# 白板推导笔记

## 系列二十二 谱聚类

- 损失函数 cut -》$N_{cut}$ 规范化cut

<p align="center">
  <img src="https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/wEw1Ik.jpg" style="zoom:100%" />
</p>
<p align="center">
  <img src="https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/tQQAOY.jpg" style="zoom:100%" />
</p>

- $O^{'}$ 与 $O$ 不一样，但由于乘以对角矩阵，再求trace，所以运算的结果是一样的（相当于其他的数据没有利用到）

<p align="center">
  <img src="https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/hxJZIR.jpg" style="zoom:100%" />
</p>



## 系列二十三 前馈神经网络

### 从机器学习到深度学习（开启新的篇章）

<p align="center">
  <img src="https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/4gMZlM.jpg" style="zoom:100%" />
</p>

### 从感知机到深度学习

<p align="center">
  <img src="https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/9TtSoM.jpg" style="zoom:100%" />
</p>

### 非线性问题的三种解决方法

<p align="center">
  <img src="https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/mTxziE.jpg" style="zoom:100%" />
</p>

<p align="center">
  <img src="https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/hZkJUs.jpg" style="zoom:100%" />
</p>

<p align="center">
  <img src="https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/seUwQx.jpg" style="zoom:100%" />
</p>

<p align="center">
  <img src="https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/ZtkWMh.jpg" style="zoom:100%" />
</p>

- 虽然高维空间比低维空间更易线性可分，但是手动设计非线性转换比较复杂，可行性值得商榷
- kernel trick ，隐含转换，不用手动设计
- 神经网络 异或 理解

<p align="center">
  <img src="https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/FYbKvN.jpg" style="zoom:100%" />
</p>

<p align="center">
  <img src="https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/tGpoGd.jpg" style="zoom:100%" />
</p>

