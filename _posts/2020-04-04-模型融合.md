---
layout:     post
title:      模型融合
subtitle:   天池比赛二手车价格预测
date:       2020-04-04
author:     Young
header-img: img/bg-post/1*EbpKczfURCvAF6uUp_Hhew.jpeg
catalog: true
tags:
    - tianchi

---

### 模型融合介绍

模型融合是比赛后期一个重要的环节，大体来说有如下的类型方式。

1.  **简单加权融合**:
    - 回归（分类概率）：算术平均融合（Arithmetic mean），几何平均融合（Geometric mean）；
    - 分类：投票（Voting)
    - 综合：排序融合(Rank averaging)，log融合


2.  **stacking/blending**:
    - 构建多层模型，并利用预测结果再拟合预测。

3. **boosting/bagging**（在xgboost，Adaboost,GBDT中已经用到）:
   - 多树的提升方法

### Stacking相关理论介绍

简单来说 stacking 就是当用初始训练数据学习出若干个基学习器后，将这几个学习器的预测结果作为新的训练集，来学习一个新的学习器。

![Tk0x5R](https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/Tk0x5R.jpg)

![C1YFHJ](https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/C1YFHJ.jpg)

- 过程1-3 是训练出来个体学习器，也就是初级学习器。
- 过程5-9是 使用训练出来的个体学习器来得预测的结果，这个预测的结果当做次级学习器的训练集。
- 过程11 是用初级学习器预测的结果训练出次级学习器，得到我们最后训练的模型。

> 两层堆叠的一种基本的原始思路想法：在不同模型预测的结果基础上再加一层模型，进行再训练（把前一层的输出当作当前层的输入），从而得到模型最终的预测。

Stacking本质上就是这么直接的思路，但是直接这样有时对于**如果训练集和测试集分布不那么一致**的情况下是有一点问题的，其问题在于用初始模型训练的标签再利用真实标签进行再训练，毫无疑问会导致一定的模型过拟合训练集，这样或许模型在测试集上的泛化能力或者说效果会有一定的下降，因此现在的问题变成了如何降低再训练的过拟合性，这里我们一般有两种方法。

- 次级模型尽量选择简单的线性模型
- **利用K折交叉验证**

![hlPmEG](https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/hlPmEG.jpg)

![llMQ6R](https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/llMQ6R.jpg)

```python
#5折stacking
n_splits = 5
skf = StratifiedKFold(n_splits)
skf = skf.split(X, y)

for j, clf in enumerate(clfs):
    #依次训练各个单模型
    dataset_blend_test_j = np.zeros((X_predict.shape[0], 5))
    for i, (train, test) in enumerate(skf):
        #5-Fold交叉训练，使用第i个部分作为预测，剩余的部分来训练模型，获得其预测的输出作为第i部分的新特征。
        X_train, y_train, X_test, y_test = X[train], y[train], X[test], y[test]
        clf.fit(X_train, y_train)
        y_submission = clf.predict_proba(X_test)[:, 1]
        dataset_blend_train[test, j] = y_submission
        dataset_blend_test_j[:, i] = clf.predict_proba(X_predict)[:, 1]
    #对于测试集，直接用这k个模型的预测值均值作为新的特征。
    dataset_blend_test[:, j] = dataset_blend_test_j.mean(1)
    print("val auc Score: %f" % roc_auc_score(y_predict, dataset_blend_test[:, j]))

clf = LogisticRegression(solver='lbfgs')
clf.fit(dataset_blend_train, y)
y_submission = clf.predict_proba(dataset_blend_test)[:, 1]
```

比赛的融合这个问题，个人的看法来说其实涉及多个层面，也是提分和提升模型鲁棒性的一种重要方法：

- 1）**结果层面的融合**，这种是最常见的融合方法，其可行的融合方法也有很多，比如根据结果的得分进行加权融合，还可以做Log，exp处理等。在做结果融合的时候，有一个很重要的条件是模型结果的得分要比较近似，然后结果的差异要比较大，这样的结果融合往往有比较好的效果提升。
- 2）**特征层面的融合**，这个层面其实感觉不叫融合，准确说可以叫分割，很多时候如果我们用同种模型训练，可以把特征进行切分给不同的模型，然后在后面进行模型或者结果融合有时也能产生比较好的效果。
- 3）**模型层面的融合**，模型层面的融合可能就涉及模型的堆叠和设计，比如加Staking层，部分模型的结果作为特征输入等，这些就需要多实验和思考了，基于模型层面的融合最好不同模型类型要有一定的差异，用同种模型不同的参数的收益一般是比较小的。

---

## Stacked Generalization & Blending

Averaging prediction files is nice and easy, but it’s not the only method that the [top Kagglers](https://www.kaggle.com/users) are using. The serious gains start with stacking and blending.

#### 1.Ensemble through Stacked Generalization

The basic idea behind stacked generalization is to **use a pool of base classifiers, then using another classifier to combine their predictions**, with the aim of reducing the generalization error.

**A stacker model gets more information on the problem space** by using the first-stage predictions as features, than if it was trained in isolation.

- Stacking with logistic regression
- Stacking with non-linear algorithms
- Feature weighted linear stacking
- Quadratic linear stacking of models
- Stacking classifiers with regressors and vice versa
- Stacking unsupervised learned features
- Online Stacking


#### 2.Ensemble through Blending

Blending is a word introduced by the Netflix winners. It is very close to stacked generalization, but a bit simpler and less risk of an information leak. Some researchers use “stacked ensembling” and “blending” interchangeably.

With blending, instead of creating out-of-fold predictions for the train set, you create **a small holdout set of say 10% of the train set**. **The stacker model then trains on this holdout set only**.

Blending has a few benefits:

- It is simpler than stacking.
- It wards against an information leak: The generalizers and stackers use different data.
- You do not need to share a seed for stratified folds with your teammates. Anyone can throw models in the ‘blender’ and the blender decides if it wants to keep that model or not.

The cons are:

- You use less data overall
- The final model may overfit to the holdout set.
- Your CV is more solid with stacking (calculated over more folds) than using a single small holdout set.

