---
title: "潜在语义分析"
subtitle: "latent semantic analysis"
layout: post
author: "echisenyang"
header-style: text
hidden: true
catalog: true
tags:
  - 输出计划
  - 李航统计学习第二版
---



![17.潜在语义分析-2](https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/17.潜在语义分析-2.jpg)



## 潜在语义分析

潜在语义分析（latent semantic analysis， LSA）是一种无监督学习方法，主要用于**文本的话题分析**，其特点是**通过矩阵分解发现文本与单词之间的基于话题的语义关系**。

文本信息处理中，传统的方法以单词向量表示文本的语义内容，以单词向量空间的度量表示文本之间的语义相似度。**潜在语义分析旨在解决这种方法不能准确表示语义的问题**，试图从大量的文本数据中**发现潜在的话题**，**以话题向量表示文本的语义内容**，**以话题向量空间的度量更准确地表示文本之间的语义相似度**。这也是话题分析（topic modeling）的基本想法。

潜在语义分析使用的是非概率的话题分析模型。具体地，**将文本集合表示为单词一文本矩阵，对单词一文本矩阵进行奇异值分解，从而得到话题向量空间，以及文本在话题向量空间的表示**。



### 单词向量空间模型的优点及其缺陷

直观上，**在两个文本中共同出现的单词越多，其语义内容就越相近，这时，对应的单词向量同不为零的维度就越多，内积就越大（单词向量元素的值都是非负的），表示两个文本在语义内容上越相似**。这个模型虽然简单，却能很好地表示文本之间的语义相似度，与人们对语义相似度的判断接近，在一定程度上能够满足应用的需求，至今仍在文本信息检索、文本数据挖掘等领域被广泛使用，可以认为是文本信息处理的一个基本原理。

<img src="https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/XGVPTA.png" alt="XGVPTA" style="zoom:50%;" />

**单词向量空间模型的优点**

- **模型简单**，**计算效率高**。因为单词向量通常是稀疏的，两个向量的内积计算只需要在其同不为零的维度上进行即可，需要的计算很少，可以高效地完成。

**单词向量空间模型也有一定的局限性**

- 体现在内积相似度未必能够准确表达两个文本的语义相似度上。
  - 因为自然语言的单词具有**一词多义性**（polysemy），即同一个单词可以表示多个语义
  - **多词一义性**（synonymy），即多个单词可以表示同一个语义，所以基于单词向量的相似度计算存在不精确的问题。



### 话题向量空间

**两个文本的语义相似度可以体现在两者的话题相似度上**。

- 所谓**话题**（topic），并没有严格的定义，就是指**文本所讨论的内容或主题**。**一个文本一般含有若干个话题**。**如果两个文本的话题相似，那么两者的语义应该也相似**。
- **话题可以由若干个语义相关的单词表示**，**<font color=red>同义词（如“airplane"与“aircraft"）可以表示同一个话题，而多义词（如“apple"）可以表示不同的话题</font>**。这样，**基于话题的模型就可以解决上述基于单词的模型存在的问题。**
- 可以设想定义一种话题向量空间模型（topic vector space model）。给定一个文本，**用话题空间的一个向量表示该文本，该向量的每一分量对应一个话题，其数值为该话题在该文本中出现的权值**。用两个向量的内积或标准化内积表示对应的两个文本的语义相似度。**注意话题的个数通常远远小于单词的个数，话题向量空间模型更加抽象**。事实上潜在语义分析正是构建话题向量空间的方法（即话题分析的方法），单词向量空间模型与话题向量空间模型可以互为补充，现实中，两者可以同时使用。



### 潜在语义分析算法

- 截断奇异值分解

<img src="https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/XnTiJn.png" alt="XnTiJn" style="zoom:50%;" />

![ZUc9Vs](https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/ZUc9Vs.png)

- 非负矩阵分解

![kntcsh](https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/kntcsh.png)

- 然后将问题转为最优化问题，再用“乘法更新规则”求解

考虑求解最优化问题$\begin{array}{cc}\min _{W, H} & \|X-W H\|^{2} \\ \text { s.t. } & W, H \geqslant 0\end{array}$和问题 $\begin{array}{cc}\min _{W, H} & D(X \| W H) \\ \text { s.t. } & W, H \geqslant 0\end{array}$ 。由于目标函数 $\|X-W H\|^{2}$ 和 $D(X \| W H)$ 只是对变量 W 和 H 之一的凸函数，而不是同时对两个变量的凸函数，因此**找到全局最优（最小值）比较困难，可以通过数值最优化方法求局部最优（极小值）**。**梯度下降法**比较容易实现，但是收敛速度慢。**共轭梯度法**收敛速度快，但实现比较复杂。Lee和Seung提出了新的基于“**乘法更新规则**”的优化算法，交替地对W和H进行更新。

<img src="https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/AHABmj.jpg" alt="AHABmj" style="zoom:50%;" />

