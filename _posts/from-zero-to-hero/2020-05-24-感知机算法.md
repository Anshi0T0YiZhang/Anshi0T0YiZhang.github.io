---
title: "感知机算法"
subtitle: "PLA"
layout: post
author: "echisenyang"
header-style: text
hidden: true
catalog: true
tags:
  - 输出计划
  - 李航统计学习第二版
---



### 从机器学习到深度学习

<p align="center">
  <img src="https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/4gMZlM.jpg" style="zoom:100%" />
</p>

### 从感知机到深度学习

<p align="center">
  <img src="https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/9TtSoM.jpg" style="zoom:100%" />
</p>

### 感知机

![2.感知机-1](https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/2.感知机-1.jpg)

![2.感知机-2](https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/2.感知机-2.jpg)

#### 模型+策略+算法

- 模型：感知机对应分离超平面
- 策略：基于误分类的损失函数
- 算法：梯度下降法对损失函数极小化

感知机（perceptron）是**二类分类的线性分类模型**，其输入为实例的特征向量，输出为实例的类别，取+1 和-1 二值。感知机**对应于输入空间（特征空间）中将实例划分为正负两类的分离超平面**，属于判别模型。感知机学习**旨在求出将训练数据进行线性划分的分离超平面，为此，导入基于误分类的损失函数，利用梯度下降法对损失函数进行极小化**，求得感知机模型。

感知机学习算法具有简单而易于实现的优点，分为原始形式和对偶形式。感知机预测是用学习得到的感知机模型对新的输入实例进行分类。感知机 1957 年由 Rosenblatt 提出，是神经网络与支持向量机的基础。

#### 感知机的线性可分性

![kW5pdE](https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/kW5pdE.png)

![CA1IdE](https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/CA1IdE.png)

#### 损失函数的含义

- **0-1损失函数直接对应分类判断错误的个数**，但是它是一个非凸函数，不太适用.
- 感知机就是用的这种损失函数。**但是相等这个条件太过严格**，因此可以放宽条件，即满足 ![img](https://mmbiz.qpic.cn/mmbiz_svg/6t0VDe9bl5f74XMG3ea8ibrDymbNS423PEiaZXEibljgib0JFSYUclfOQOwu9wZSsUEUmibGlrPAy9mSJFDzruS7gFclUxgHWPYEv/640?wx_fmt=svg&wxfrom=5&wx_lazy=1&wx_co=1) 时认为相等，

<img src="https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/rM2ji1.png" alt="rM2ji1" style="zoom:50%;" />

#### 学习算法的解释（原始形式）

<img src="https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/HAQkHm.png" alt="HAQkHm" style="zoom:50%;" />

### 【感知机原始形式代码】

```python
# 原始形式 2.1
class PLA:
    def __init__(self, max_iter=1000, shuffle=False):
        self.b = 0
        self.lr = 0.1
        self.max_iter = max_iter
        self.iter = 0
        self.shuffle = shuffle
        
    def sign(self, x, w, b):
        return np.dot(x, w) + b
    
    def fit(self, X, y):
        N, M = X.shape
        self.w = np.ones(M)
        for n in range(self.max_iter):
            self.iter = n
            wrong_items = 0
            if self.shuffle: #每次迭代，是否打乱
                idx = np.random.permutation(range(N))
                X,y = X[idx],y[idx]
            # 每次迭代都是全量梯度下降（GD）
            for i in range(N):
                # 如果判定是负例，更新 w、b
                if y[i] * self.sign(X[i], self.w, self.b) <= 0:
                    self.w += self.lr * np.dot(y[i], X[i])
                    self.b += self.lr * y[i]
                    wrong_items += 1
            if wrong_items == 0:
                print("finished at iters: {}, w: {}, b: {}".format(self.iter, self.w, self.b))
                return 
        print("finished for reaching the max_iter: {}, w: {}, b: {}".format(self.max_iter, self.w, self.b))
```



#### 感知机的对偶形式

<img src="https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/UQo1OJ.png" alt="UQo1OJ" style="zoom:50%;" />

### 【感知机对偶形式代码】

```python
# 对偶形式 2.3
class PLA_dual:
    def __init__(self, max_iter=1000):
        self.b = 0
        self.lr = 0.1
        self.max_iter = max_iter
        self.iter = 0
    
    def cal_w(self, X): 
        w = 0
        # 最终的 w 是 alpha、y、x的内积和
        for i in range(len(self.alpha)):
            w += self.alpha[i]*y[i]*X[i]
        return w
    
    def gram_matrix(self, X):
        # gram矩阵：存储训练集中实例的内积 y·x
        return np.dot(X, X.T)
    
    def fit(self, X, y):
        N, M = X.shape
        self.alpha = np.zeros(N)
        gram = self.gram_matrix(X)
        for n in range(self.max_iter):
            self.iter = n
            wrong_items = 0
            # 每次迭代都是全量梯度下降（GD）
            for i in range(N):
                sigma_sum = 0
                for j in range(N):
                    sigma_sum += self.alpha[j] * y[j] * gram[i,j]
                sigma_sum += self.b
                # 如果判定是负例，更新 alpha、b
                if y[i] * sigma_sum <= 0:
                    self.alpha[i] += self.lr
                    self.b += self.lr * y[i]
                    wrong_items += 1
            if wrong_items == 0:
                self.w = self.cal_w(X)
                print("finished at iters: {}, w: {}, b: {}".format(self.iter, self.w, self.b))
                return
        self.w = self.cal_w(X)
        print("finished for reaching the max_iter: {}, w: {}, b: {}".format(self.max_iter, self.w, self.b))
        return
```



#### 感知机算法的收敛性与初值选择

<img src="https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/V0n0SU.png" alt="V0n0SU" style="zoom:50%;" />





