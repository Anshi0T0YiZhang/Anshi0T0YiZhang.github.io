---
title: "EM算法"
subtitle: "EM algorithm"
layout: post
author: "echisenyang"
header-style: text
hidden: true
catalog: true
tags:
  - 输出计划
  - 李航统计学习第二版
---



### EM算法适用问题（估计含有隐变量的概率模型参数）

概率模型有时既含有**观测变量**（observable variable），又含有**隐变量或潜在变量**（latent variable）。**如果概率模型的变量都是观测变量，那么给定数据，可以直接用极大似然估计法，或贝叶斯估计法估计模型参数**。

但是，当模型含有隐变量时，就不能简单地使用这些估计方法。**EM算法就是含有隐变量的概率模型参数的极大似然估计法，或极大后验概率估计法**。我们仅讨论极大似然估计，极大后验概率估计与其类似。



### E步与M步的由来

Suppose we have an estimation problem in which we have a training set $\{x (1), . . . , x(m)\}$ consisting of $m$ independent examples. We wish to **fit the parameters of a model $p(x, z)$ to the data**, where the likelihood is given by
$$
\begin{aligned} \ell(\theta) &=\sum_{i=1}^{m} \log p(x ; \theta) \\ &=\sum_{i=1}^{m} \log \sum_{z} p(x, z ; \theta) \end{aligned}
$$
But, explicitly finding the maximum likelihood estimates of the parameters $θ$ may be hard. Here, **the $z (i) ’s$ are the latent random variables**; and it is often the case that **if the $z (i) ’s$ were observed, then maximum likelihood estimation would be easy**. 

- 直接求解析解是困难的，因此EM算法转而用迭代的方式求的近似解。our strategy will be to instead repeatedly construct a lower-bound on (E-step), and then optimize that lower-bound (M-step).

- 构造EM算法中的 $Q$ 函数：**the posterior distribution of the $z (i) ’s$，即隐变量的后验概率** 

<img src="https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/MIpk3k.png" alt="MIpk3k" style="zoom:50%;" />

- where the **“$z (i) ∼ Qi$” subscripts above indicate that the expectations are with respect to $z (i)$ drawn from $Qi$** . This allowed us to go from $Equation (2)$ to $Equation (3)$.

- Now, for any set of distributions $Qi$ , the $formula (3)$ gives a lower-bound on ($θ$). **There’re many possible choices for the $Qi ’s$. Which should we choose?** Well, if we have some current guess $θ$ of the parameters, it seems natural to try to make the lower-bound tight at that value of $θ$. I.e., we’ll make the inequality above hold with equality at our particular value of $θ$. (We’ll see later how this enables us to prove that ($θ$) increases monotonically with successive iterations of EM.)

<img src="https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/zDEVYS.png" alt="zDEVYS" style="zoom:50%;" />

- **EM algorithm**

<img src="https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/A5zclu.png" alt="A5zclu" style="zoom:50%;" />

